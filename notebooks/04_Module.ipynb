{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# Module 4: Geometric Transformations\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/computer-graphics/blob/main/notebooks/04_Module.ipynb)\n",
    "\n",
    "**Week 7-8: Translation, Rotation, Scaling, Affine & Perspective Transformations**\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand geometric transformation theory\n",
    "- Apply affine transformations (rotation, scaling, translation, shear)\n",
    "- Work with homogeneous coordinates\n",
    "- Implement perspective transformations\n",
    "- Perform image warping and remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-theory-intro",
   "metadata": {},
   "source": [
    "---\n",
    "## Mathematical Foundations: Transformation Theory\n",
    "\n",
    "### Topics Covered\n",
    "1. **Homogeneous Coordinates**: Unified representation for all transformations\n",
    "2. **Affine Transformations**: Translation, rotation, scaling, shear\n",
    "3. **Transformation Matrices**: 2D and 3D representations\n",
    "4. **Matrix Composition**: Combining multiple transformations\n",
    "5. **Perspective Transformations**: Projective geometry\n",
    "6. **Interpolation Methods**: Image resampling theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-homogeneous-theory",
   "metadata": {},
   "source": [
    "### 1. Homogeneous Coordinates\n",
    "\n",
    "#### Why Homogeneous Coordinates?\n",
    "\n",
    "In **standard Cartesian coordinates**, different transformations require different operations:\n",
    "- Rotation: Matrix multiplication\n",
    "- Scaling: Matrix multiplication\n",
    "- Translation: Vector addition (not matrix multiplication!)\n",
    "\n",
    "**Problem**: Cannot represent all transformations as matrix multiplication.\n",
    "\n",
    "**Solution**: Use **homogeneous coordinates** - add an extra dimension!\n",
    "\n",
    "#### Definition\n",
    "\n",
    "A 2D point $(x, y)$ in **homogeneous coordinates** becomes:\n",
    "\n",
    "$$\n",
    "\\mathbf{p} = \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Or more generally:\n",
    "\n",
    "$$\n",
    "\\mathbf{p} = \\begin{bmatrix} wx \\\\ wy \\\\ w \\end{bmatrix}, \\quad w \\neq 0\n",
    "$$\n",
    "\n",
    "**Conversion back to Cartesian**:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} wx/w \\\\ wy/w \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Key Benefits\n",
    "\n",
    "1. **Unified representation**: All transformations are matrix multiplication\n",
    "2. **Easy composition**: Multiply transformation matrices\n",
    "3. **Handles infinity**: Points at infinity have $w = 0$\n",
    "4. **Perspective division**: Natural handling of perspective projection\n",
    "\n",
    "#### Translation in Homogeneous Coordinates\n",
    "\n",
    "**Standard coordinates** (addition):\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} + \\begin{bmatrix} t_x \\\\ t_y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Homogeneous coordinates** (matrix multiplication!):\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & t_x \\\\\n",
    "0 & 1 & t_y \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-homogeneous-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate homogeneous coordinates\n",
    "print(\"=\" * 70)\n",
    "print(\"HOMOGENEOUS COORDINATES: DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define a point in Cartesian coordinates\n",
    "point_cartesian = np.array([3, 4])\n",
    "print(f\"\\nCartesian coordinates: {point_cartesian}\")\n",
    "\n",
    "# Convert to homogeneous coordinates\n",
    "point_homogeneous = np.array([3, 4, 1])\n",
    "print(f\"Homogeneous coordinates: {point_homogeneous}\")\n",
    "\n",
    "# Different homogeneous representations (same point)\n",
    "point_h2 = np.array([6, 8, 2])  # 2x scale\n",
    "point_h3 = np.array([9, 12, 3])  # 3x scale\n",
    "\n",
    "print(f\"\\nAlternative homogeneous representations:\")\n",
    "print(f\"  [3, 4, 1]   → ({point_h2[0]/point_h2[2]}, {point_h2[1]/point_h2[2]})\")\n",
    "print(f\"  [6, 8, 2]   → ({point_h2[0]/point_h2[2]}, {point_h2[1]/point_h2[2]})\")\n",
    "print(f\"  [9, 12, 3]  → ({point_h3[0]/point_h3[2]}, {point_h3[1]/point_h3[2]})\")\n",
    "print(f\"\\nAll represent the same point: ({point_cartesian[0]}, {point_cartesian[1]})\")\n",
    "\n",
    "# Translation using homogeneous coordinates\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSLATION VIA MATRIX MULTIPLICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Translation vector\n",
    "t_x, t_y = 5, 3\n",
    "\n",
    "# Translation matrix\n",
    "T = np.array([\n",
    "    [1, 0, t_x],\n",
    "    [0, 1, t_y],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "print(f\"\\nTranslation matrix T (translate by ({t_x}, {t_y})):\")\n",
    "print(T)\n",
    "\n",
    "# Apply translation\n",
    "point_translated_h = T @ point_homogeneous\n",
    "point_translated = point_translated_h[:2] / point_translated_h[2]\n",
    "\n",
    "print(f\"\\nOriginal point: {point_cartesian}\")\n",
    "print(f\"After translation: {point_translated}\")\n",
    "print(f\"Expected: {point_cartesian + np.array([t_x, t_y])}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Original point\n",
    "ax.scatter(point_cartesian[0], point_cartesian[1], s=200, c='blue', \n",
    "           marker='o', label='Original', zorder=5)\n",
    "ax.annotate(f'  ({point_cartesian[0]}, {point_cartesian[1]})', \n",
    "            (point_cartesian[0], point_cartesian[1]),\n",
    "            fontsize=12, color='blue')\n",
    "\n",
    "# Translated point\n",
    "ax.scatter(point_translated[0], point_translated[1], s=200, c='red',\n",
    "           marker='s', label='Translated', zorder=5)\n",
    "ax.annotate(f'  ({point_translated[0]:.0f}, {point_translated[1]:.0f})',\n",
    "            (point_translated[0], point_translated[1]),\n",
    "            fontsize=12, color='red')\n",
    "\n",
    "# Arrow showing translation\n",
    "ax.arrow(point_cartesian[0], point_cartesian[1],\n",
    "         t_x, t_y, head_width=0.3, head_length=0.2,\n",
    "         fc='green', ec='green', linewidth=2, alpha=0.7,\n",
    "         label=f'Translation ({t_x}, {t_y})')\n",
    "\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='k', linewidth=0.5)\n",
    "ax.axvline(x=0, color='k', linewidth=0.5)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_title('Translation Using Homogeneous Coordinates', fontsize=14)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: Homogeneous coordinates allow ALL transformations\")\n",
    "print(\"to be represented as matrix multiplication!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-affine-theory",
   "metadata": {},
   "source": [
    "### 2. Affine Transformations\n",
    "\n",
    "An **affine transformation** preserves:\n",
    "- Points lying on a line remain on a line (collinearity)\n",
    "- Parallel lines remain parallel\n",
    "- Ratios of distances along lines\n",
    "\n",
    "#### General Form\n",
    "\n",
    "In 2D homogeneous coordinates:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & t_x \\\\\n",
    "a_{21} & a_{22} & t_y \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Or in block form:\n",
    "\n",
    "$$\n",
    "\\mathbf{p}' = \\begin{bmatrix} A & \\mathbf{t} \\\\ \\mathbf{0}^T & 1 \\end{bmatrix} \\mathbf{p}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $A \\in \\mathbb{R}^{2 \\times 2}$: Linear transformation (rotation, scaling, shear)\n",
    "- $\\mathbf{t} \\in \\mathbb{R}^2$: Translation vector\n",
    "\n",
    "#### Basic Affine Transformations\n",
    "\n",
    "**1. Translation**:\n",
    "$$\n",
    "T(t_x, t_y) = \\begin{bmatrix}\n",
    "1 & 0 & t_x \\\\\n",
    "0 & 1 & t_y \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**2. Scaling**:\n",
    "$$\n",
    "S(s_x, s_y) = \\begin{bmatrix}\n",
    "s_x & 0 & 0 \\\\\n",
    "0 & s_y & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**3. Rotation** (counterclockwise by angle $\\theta$):\n",
    "$$\n",
    "R(\\theta) = \\begin{bmatrix}\n",
    "\\cos\\theta & -\\sin\\theta & 0 \\\\\n",
    "\\sin\\theta & \\cos\\theta & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**4. Shear** (horizontal):\n",
    "$$\n",
    "H_x(m) = \\begin{bmatrix}\n",
    "1 & m & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**5. Reflection** (across y-axis):\n",
    "$$\n",
    "F_y = \\begin{bmatrix}\n",
    "-1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-affine-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample image\n",
    "!wget -q https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/481px-Cat03.jpg -O cat.jpg\n",
    "img = cv2.imread('cat.jpg')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-translation",
   "metadata": {},
   "source": [
    "## 4.1 Translation\n",
    "\n",
    "**Mathematical definition**:\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} + \\begin{bmatrix} t_x \\\\ t_y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "OpenCV uses a **2×3 affine matrix** (projection of 3×3 homogeneous matrix):\n",
    "$$\n",
    "M = \\begin{bmatrix} 1 & 0 & t_x \\\\ 0 & 1 & t_y \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-translation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation matrix\n",
    "t_x, t_y = 100, 50\n",
    "M_translate = np.float32([\n",
    "    [1, 0, t_x],\n",
    "    [0, 1, t_y]\n",
    "])\n",
    "\n",
    "print(\"Translation matrix M (2×3):\")\n",
    "print(M_translate)\n",
    "print(f\"\\nTranslation: ({t_x}, {t_y})\")\n",
    "\n",
    "# Apply translation\n",
    "img_translated = cv2.warpAffine(img, M_translate, (w, h))\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(img_translated, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Translated by ({t_x}, {t_y})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-rotation",
   "metadata": {},
   "source": [
    "## 4.2 Rotation\n",
    "\n",
    "**Rotation around origin** by angle $\\theta$:\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta & -\\sin\\theta \\\\\n",
    "\\sin\\theta & \\cos\\theta\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Rotation around arbitrary center** $(c_x, c_y)$:\n",
    "1. Translate center to origin: $T(-c_x, -c_y)$\n",
    "2. Rotate: $R(\\theta)$\n",
    "3. Translate back: $T(c_x, c_y)$\n",
    "\n",
    "**Combined matrix**:\n",
    "$$\n",
    "M = T(c_x, c_y) \\cdot R(\\theta) \\cdot T(-c_x, -c_y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-rotation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation parameters\n",
    "center = (w // 2, h // 2)\n",
    "angle = 45  # degrees\n",
    "scale = 1.0\n",
    "\n",
    "# Get rotation matrix using OpenCV\n",
    "M_rotate = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "print(f\"Rotation matrix (2×3):\")\n",
    "print(M_rotate)\n",
    "print(f\"\\nCenter: {center}\")\n",
    "print(f\"Angle: {angle}°\")\n",
    "print(f\"Scale: {scale}\")\n",
    "\n",
    "# Manual construction\n",
    "theta = np.radians(angle)\n",
    "cos_theta = np.cos(theta)\n",
    "sin_theta = np.sin(theta)\n",
    "\n",
    "print(f\"\\nManual calculation:\")\n",
    "print(f\"  cos({angle}°) = {cos_theta:.6f}\")\n",
    "print(f\"  sin({angle}°) = {sin_theta:.6f}\")\n",
    "\n",
    "# Apply rotation\n",
    "img_rotated = cv2.warpAffine(img, M_rotate, (w, h))\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].plot(center[0], center[1], 'r+', markersize=15, markeredgewidth=2)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(img_rotated, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Rotated {angle}° around center')\n",
    "axes[1].plot(center[0], center[1], 'r+', markersize=15, markeredgewidth=2)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-scaling",
   "metadata": {},
   "source": [
    "## 4.3 Scaling\n",
    "\n",
    "**Mathematical definition**:\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "s_x & 0 \\\\\n",
    "0 & s_y\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- $s_x, s_y > 1$: Enlargement\n",
    "- $0 < s_x, s_y < 1$: Reduction\n",
    "- $s_x = s_y$: Uniform scaling\n",
    "- $s_x \\neq s_y$: Non-uniform scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-scaling-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling factors\n",
    "scale_x, scale_y = 1.5, 1.5\n",
    "\n",
    "# Method 1: Using cv2.resize()\n",
    "new_w = int(w * scale_x)\n",
    "new_h = int(h * scale_y)\n",
    "img_scaled_resize = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Method 2: Using warpAffine\n",
    "M_scale = np.float32([\n",
    "    [scale_x, 0, 0],\n",
    "    [0, scale_y, 0]\n",
    "])\n",
    "img_scaled_warp = cv2.warpAffine(img, M_scale, (new_w, new_h))\n",
    "\n",
    "print(f\"Original size: {w} × {h}\")\n",
    "print(f\"Scale factors: ({scale_x}, {scale_y})\")\n",
    "print(f\"New size: {new_w} × {new_h}\")\n",
    "print(f\"\\nScaling matrix M:\")\n",
    "print(M_scale)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(f'Original\\n{w}×{h}')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(img_scaled_resize, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Scaled (cv2.resize)\\n{new_w}×{new_h}')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(img_scaled_warp, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title(f'Scaled (warpAffine)\\n{new_w}×{new_h}')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-composition",
   "metadata": {},
   "source": [
    "## 4.4 Transformation Composition\n",
    "\n",
    "**Order matters!** Matrix multiplication is not commutative.\n",
    "\n",
    "**Example**: Rotate then translate vs Translate then rotate\n",
    "\n",
    "$$\n",
    "M_1 = T \\cdot R \\quad \\text{(rotate around origin, then translate)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "M_2 = R \\cdot T \\quad \\text{(translate, then rotate around origin)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "M_1 \\neq M_2\n",
    "$$\n",
    "\n",
    "**Common operation**: Rotate around center with scaling\n",
    "$$\n",
    "M = T(c_x, c_y) \\cdot S(s) \\cdot R(\\theta) \\cdot T(-c_x, -c_y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-composition-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate order dependency\n",
    "print(\"=\" * 70)\n",
    "print(\"TRANSFORMATION ORDER MATTERS!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a small test shape\n",
    "test_img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "pts = np.array([[50, 100], [150, 100], [100, 50]], dtype=np.int32)\n",
    "cv2.fillPoly(test_img, [pts], (0, 255, 0))\n",
    "\n",
    "# Transformation parameters\n",
    "angle = 30\n",
    "tx, ty = 100, 50\n",
    "\n",
    "# Method 1: Rotate then Translate\n",
    "M_rot = cv2.getRotationMatrix2D((50, 50), angle, 1.0)\n",
    "M_trans = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "\n",
    "# Compose: T * R (apply R first, then T)\n",
    "# Need to convert to 3x3 for multiplication\n",
    "M_rot_3x3 = np.vstack([M_rot, [0, 0, 1]])\n",
    "M_trans_3x3 = np.vstack([M_trans, [0, 0, 1]])\n",
    "\n",
    "M_1 = M_trans_3x3 @ M_rot_3x3\n",
    "M_1_2x3 = M_1[:2, :]\n",
    "\n",
    "result1 = cv2.warpAffine(test_img, M_1_2x3, (300, 300))\n",
    "\n",
    "# Method 2: Translate then Rotate\n",
    "M_2 = M_rot_3x3 @ M_trans_3x3\n",
    "M_2_2x3 = M_2[:2, :]\n",
    "\n",
    "result2 = cv2.warpAffine(test_img, M_2_2x3, (300, 300))\n",
    "\n",
    "print(f\"\\nTransformation 1: Rotate {angle}°, then translate ({tx}, {ty})\")\n",
    "print(f\"Matrix M1 = T × R:\")\n",
    "print(M_1_2x3)\n",
    "\n",
    "print(f\"\\nTransformation 2: Translate ({tx}, {ty}), then rotate {angle}°\")\n",
    "print(f\"Matrix M2 = R × T:\")\n",
    "print(M_2_2x3)\n",
    "\n",
    "print(f\"\\nMatrices are different: {not np.allclose(M_1_2x3, M_2_2x3)}\")\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(result1, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Rotate → Translate\\n(T × R)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(result2, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title(f'Translate → Rotate\\n(R × T)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: Transformation order changes the result!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-perspective-theory",
   "metadata": {},
   "source": [
    "## 4.5 Perspective Transformation\n",
    "\n",
    "**Perspective transformations** (projective transformations) are more general than affine.\n",
    "\n",
    "#### Mathematical Definition\n",
    "\n",
    "Full 3×3 homogeneous transformation:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} wx' \\\\ wy' \\\\ w \\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "h_{11} & h_{12} & h_{13} \\\\\n",
    "h_{21} & h_{22} & h_{23} \\\\\n",
    "h_{31} & h_{32} & h_{33}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Perspective division** to get Cartesian coordinates:\n",
    "\n",
    "$$\n",
    "x' = \\frac{h_{11}x + h_{12}y + h_{13}}{h_{31}x + h_{32}y + h_{33}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "y' = \\frac{h_{21}x + h_{22}y + h_{23}}{h_{31}x + h_{32}y + h_{33}}\n",
    "$$\n",
    "\n",
    "#### Properties\n",
    "\n",
    "- **Preserves**: Lines remain lines\n",
    "- **Does NOT preserve**: Parallelism, angles, distances\n",
    "- **8 degrees of freedom**: 9 parameters, but scale-invariant\n",
    "- **Requires**: 4 point correspondences to solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-perspective-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective transformation example: Document scanner\n",
    "print(\"=\" * 70)\n",
    "print(\"PERSPECTIVE TRANSFORMATION: DOCUMENT RECTIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a tilted rectangle image\n",
    "doc_img = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
    "cv2.rectangle(doc_img, (50, 50), (550, 350), (200, 200, 200), -1)\n",
    "cv2.putText(doc_img, 'DOCUMENT', (200, 220), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            2, (0, 0, 0), 3)\n",
    "\n",
    "# Source points (quadrilateral - perspective view)\n",
    "src_pts = np.float32([\n",
    "    [100, 150],  # Top-left\n",
    "    [500, 100],  # Top-right\n",
    "    [50, 350],   # Bottom-left\n",
    "    [550, 300]   # Bottom-right\n",
    "])\n",
    "\n",
    "# Destination points (rectangle - frontal view)\n",
    "dst_pts = np.float32([\n",
    "    [0, 0],      # Top-left\n",
    "    [400, 0],    # Top-right\n",
    "    [0, 300],    # Bottom-left\n",
    "    [400, 300]   # Bottom-right\n",
    "])\n",
    "\n",
    "# Calculate perspective transformation matrix\n",
    "M_perspective = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "\n",
    "print(\"\\nPerspective transformation matrix H (3×3):\")\n",
    "print(M_perspective)\n",
    "print(f\"\\nSource points (quadrilateral):\")\n",
    "print(src_pts)\n",
    "print(f\"\\nDestination points (rectangle):\")\n",
    "print(dst_pts)\n",
    "\n",
    "# Apply perspective transformation\n",
    "rectified = cv2.warpPerspective(doc_img, M_perspective, (400, 300))\n",
    "\n",
    "# Visualize source quadrilateral\n",
    "doc_img_viz = doc_img.copy()\n",
    "cv2.polylines(doc_img_viz, [src_pts.astype(np.int32)], True, (0, 0, 255), 3)\n",
    "for i, pt in enumerate(src_pts):\n",
    "    cv2.circle(doc_img_viz, tuple(pt.astype(int)), 8, (255, 0, 0), -1)\n",
    "    cv2.putText(doc_img_viz, str(i), tuple(pt.astype(int) + 15),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].imshow(cv2.cvtColor(doc_img_viz, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Perspective View\\n(4 source points marked)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(rectified, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Rectified (Frontal View)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Application: Document scanning, camera calibration, AR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-interpolation",
   "metadata": {},
   "source": [
    "## 4.6 Interpolation Methods\n",
    "\n",
    "When transforming images, output pixels map to **non-integer** input coordinates.\n",
    "\n",
    "**Interpolation** estimates pixel values at fractional positions.\n",
    "\n",
    "### Nearest Neighbor\n",
    "$$\n",
    "f(x, y) = f(\\text{round}(x), \\text{round}(y))\n",
    "$$\n",
    "\n",
    "- Fastest\n",
    "- Produces blocky results\n",
    "\n",
    "### Bilinear Interpolation\n",
    "\n",
    "Linear interpolation in both directions:\n",
    "\n",
    "$$\n",
    "f(x, y) = (1-a)(1-b)f(x_0, y_0) + a(1-b)f(x_1, y_0) + (1-a)bf(x_0, y_1) + abf(x_1, y_1)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $x_0 = \\lfloor x \\rfloor$, $x_1 = \\lceil x \\rceil$\n",
    "- $y_0 = \\lfloor y \\rfloor$, $y_1 = \\lceil y \\rceil$\n",
    "- $a = x - x_0$, $b = y - y_0$\n",
    "\n",
    "### Bicubic Interpolation\n",
    "\n",
    "Uses 4×4 neighborhood with cubic polynomials:\n",
    "\n",
    "$$\n",
    "f(x, y) = \\sum_{i=0}^{3} \\sum_{j=0}^{3} a_{ij} x^i y^j\n",
    "$$\n",
    "\n",
    "- Smoother than bilinear\n",
    "- Slower computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-interpolation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare interpolation methods\n",
    "print(\"=\" * 70)\n",
    "print(\"INTERPOLATION METHODS COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Scale up by 3x to see differences\n",
    "scale_factor = 3\n",
    "new_size = (w * scale_factor, h * scale_factor)\n",
    "\n",
    "# Different interpolation methods\n",
    "img_nearest = cv2.resize(img, new_size, interpolation=cv2.INTER_NEAREST)\n",
    "img_linear = cv2.resize(img, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "img_cubic = cv2.resize(img, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "img_lanczos = cv2.resize(img, new_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "print(f\"\\nOriginal size: {w} × {h}\")\n",
    "print(f\"Scaled size: {new_size[0]} × {new_size[1]} ({scale_factor}x)\")\n",
    "print(f\"\\nInterpolation methods:\")\n",
    "print(f\"  INTER_NEAREST:  Fastest, blocky\")\n",
    "print(f\"  INTER_LINEAR:   Bilinear, good balance\")\n",
    "print(f\"  INTER_CUBIC:    Bicubic, smoother\")\n",
    "print(f\"  INTER_LANCZOS4: Highest quality, slowest\")\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 14))\n",
    "\n",
    "# Show small crop to see details\n",
    "crop = slice(200, 400), slice(200, 400)\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(img_nearest, cv2.COLOR_BGR2RGB)[crop])\n",
    "axes[0, 0].set_title('INTER_NEAREST\\n(Blocky)', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(img_linear, cv2.COLOR_BGR2RGB)[crop])\n",
    "axes[0, 1].set_title('INTER_LINEAR\\n(Bilinear)', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(img_cubic, cv2.COLOR_BGR2RGB)[crop])\n",
    "axes[1, 0].set_title('INTER_CUBIC\\n(Bicubic)', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(img_lanczos, cv2.COLOR_BGR2RGB)[crop])\n",
    "axes[1, 1].set_title('INTER_LANCZOS4\\n(Highest Quality)', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: Better interpolation = smoother but slower!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Homogeneous Coordinates**: Unified matrix representation for all transformations\n",
    "2. **Affine Transformations**: Preserve collinearity and parallelism\n",
    "3. **Perspective Transformations**: Most general linear transformation of 2D space\n",
    "4. **Transformation Composition**: Order matters!\n",
    "5. **Interpolation**: Critical for image quality\n",
    "\n",
    "### Transformation Hierarchy\n",
    "\n",
    "$$\n",
    "\\text{Euclidean} \\subset \\text{Similarity} \\subset \\text{Affine} \\subset \\text{Perspective}\n",
    "$$\n",
    "\n",
    "| Type | DOF | Preserves | Matrix Form |\n",
    "|------|-----|-----------|-------------|\n",
    "| Translation | 2 | Distances, angles, parallelism | $\\begin{bmatrix}1 & 0 & t_x\\\\0 & 1 & t_y\\\\0 & 0 & 1\\end{bmatrix}$ |\n",
    "| Euclidean | 3 | Distances, angles | Rotation + Translation |\n",
    "| Similarity | 4 | Angles, parallelism | Uniform scale + Rotation + Translation |\n",
    "| Affine | 6 | Parallelism, ratios | $\\begin{bmatrix}a & b & c\\\\d & e & f\\\\0 & 0 & 1\\end{bmatrix}$ |\n",
    "| Perspective | 8 | Only lines | $\\begin{bmatrix}a & b & c\\\\d & e & f\\\\g & h & 1\\end{bmatrix}$ |\n",
    "\n",
    "### OpenCV Functions Reference\n",
    "\n",
    "| Operation | Function | Key Parameters |\n",
    "|-----------|----------|----------------|\n",
    "| Translation | `cv2.warpAffine(img, M, size)` | M = 2×3 translation matrix |\n",
    "| Rotation | `cv2.getRotationMatrix2D(center, angle, scale)` | Returns 2×3 matrix |\n",
    "| Scaling | `cv2.resize(img, size, interpolation)` | INTER_NEAREST/LINEAR/CUBIC |\n",
    "| Affine | `cv2.getAffineTransform(src, dst)` | 3 point pairs → 2×3 matrix |\n",
    "| Perspective | `cv2.getPerspectiveTransform(src, dst)` | 4 point pairs → 3×3 matrix |\n",
    "| Apply Affine | `cv2.warpAffine(img, M, size)` | M is 2×3 |\n",
    "| Apply Perspective | `cv2.warpPerspective(img, M, size)` | M is 3×3 |\n",
    "\n",
    "**Next**: Module 5 - Edge Detection"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}