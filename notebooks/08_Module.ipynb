{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# Module 8: Histograms and Equalization\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/computer-graphics/blob/main/notebooks/08_Module.ipynb)\n",
    "\n",
    "**Week 13: Histogram Calculation, Equalization, CLAHE, Histogram Matching**\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand histogram theory and statistical representation\n",
    "- Calculate and visualize image histograms\n",
    "- Apply histogram equalization for contrast enhancement\n",
    "- Use adaptive histogram equalization (CLAHE)\n",
    "- Perform histogram-based image analysis and matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-warning",
   "metadata": {},
   "source": [
    "---\n",
    "## ⚠️ IMPORTANT: Run All Cells in Order\n",
    "\n",
    "**This notebook must be executed sequentially from top to bottom.**\n",
    "\n",
    "- Click **Runtime → Run all** (or **Cell → Run All**)\n",
    "- Do NOT skip cells or run them out of order\n",
    "- Each cell depends on variables from previous cells\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-theory-intro",
   "metadata": {},
   "source": [
    "---\n",
    "## Mathematical Foundations: Histogram Theory\n",
    "\n",
    "### What is a Histogram?\n",
    "\n",
    "A **histogram** is a statistical representation of the distribution of pixel intensities.\n",
    "\n",
    "**Formal definition**: For a grayscale image with intensity levels $[0, L-1]$:\n",
    "$$\n",
    "h(i) = \\text{number of pixels with intensity } i\n",
    "$$\n",
    "\n",
    "For 8-bit images: $L = 256$, so $i \\in [0, 255]$\n",
    "\n",
    "**Normalized histogram** (probability distribution):\n",
    "$$\n",
    "p(i) = \\frac{h(i)}{N}\n",
    "$$\n",
    "\n",
    "where $N$ is the total number of pixels:\n",
    "$$\n",
    "N = \\sum_{i=0}^{L-1} h(i)\n",
    "$$\n",
    "\n",
    "### Why Histograms?\n",
    "\n",
    "1. **Image analysis**: Understand intensity distribution\n",
    "2. **Contrast assessment**: Identify low/high contrast images\n",
    "3. **Thresholding**: Find optimal threshold values\n",
    "4. **Enhancement**: Improve contrast via equalization\n",
    "5. **Comparison**: Match or compare images\n",
    "6. **Segmentation**: Separate objects by intensity\n",
    "\n",
    "### Histogram Properties\n",
    "\n",
    "**Mean intensity**:\n",
    "$$\n",
    "\\mu = \\sum_{i=0}^{L-1} i \\cdot p(i)\n",
    "$$\n",
    "\n",
    "**Variance** (spread):\n",
    "$$\n",
    "\\sigma^2 = \\sum_{i=0}^{L-1} (i - \\mu)^2 \\cdot p(i)\n",
    "$$\n",
    "\n",
    "**Standard deviation**:\n",
    "$$\n",
    "\\sigma = \\sqrt{\\sigma^2}\n",
    "$$\n",
    "\n",
    "**Entropy** (information content):\n",
    "$$\n",
    "H = -\\sum_{i=0}^{L-1} p(i) \\log_2 p(i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-images",
   "metadata": {},
   "outputs": [],
   "source": "# Load test images with different characteristics\nimport urllib.request\nfrom urllib.request import Request, urlopen\n\n# For dark image, we'll use the Cat image and make it darker\nurl_base = 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/320px-Cat03.jpg'\nreq_base = Request(url_base, headers={'User-Agent': 'Mozilla/5.0'})\nwith urlopen(req_base) as response:\n    image_data = response.read()\nwith open('base.jpg', 'wb') as f:\n    f.write(image_data)\n\n# Load base image and create variations\nimg_base = cv2.imread('base.jpg', cv2.IMREAD_GRAYSCALE)\n\n# Create dark image (darken the base image)\nimg_dark = (img_base * 0.4).astype(np.uint8)\n\n# Bright image (brighten the base image)\nimg_bright = np.clip(img_base.astype(float) * 1.3 + 30, 0, 255).astype(np.uint8)\n\n# Low contrast image (reduce contrast)\nimg_low_contrast = (img_base * 0.5 + 100).astype(np.uint8)\n\n# Normal image\nimg_normal = img_base\n\nprint(f\"Loaded images:\")\nprint(f\"  Dark image: {img_dark.shape}\")\nprint(f\"  Bright image: {img_bright.shape}\")\nprint(f\"  Low contrast image: {img_low_contrast.shape}\")\nprint(f\"  Normal image: {img_normal.shape}\")\n\n# Display\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.ravel()\n\nimages = [img_dark, img_bright, img_low_contrast, img_normal]\ntitles = ['Dark Image', 'Bright Image', 'Low Contrast Image', 'Normal Image']\n\nfor i, (img, title) in enumerate(zip(images, titles)):\n    axes[i].imshow(img, cmap='gray', vmin=0, vmax=255)\n    axes[i].set_title(title)\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "cell-calc-hist",
   "metadata": {},
   "source": [
    "### 1. Calculating Histograms\n",
    "\n",
    "#### Manual Calculation\n",
    "\n",
    "```python\n",
    "histogram = np.zeros(256)\n",
    "for pixel in image.flat:\n",
    "    histogram[pixel] += 1\n",
    "```\n",
    "\n",
    "#### Using NumPy\n",
    "\n",
    "```python\n",
    "histogram, bins = np.histogram(image, bins=256, range=(0, 256))\n",
    "```\n",
    "\n",
    "#### Using OpenCV\n",
    "\n",
    "```python\n",
    "histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "```\n",
    "\n",
    "**Parameters**:\n",
    "- `images`: List of source images\n",
    "- `channels`: Channel indices (0 for grayscale)\n",
    "- `mask`: Optional mask (None for whole image)\n",
    "- `histSize`: Number of bins (256 for 8-bit)\n",
    "- `ranges`: Intensity range ([0, 256] for 8-bit)\n",
    "\n",
    "#### Color Histograms\n",
    "\n",
    "For RGB images, compute 3 separate histograms:\n",
    "$$\n",
    "h_R(i), \\quad h_G(i), \\quad h_B(i)\n",
    "$$\n",
    "\n",
    "Or multi-dimensional histograms (2D, 3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-calc-hist-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and visualize histograms\n",
    "print(\"=\" * 70)\n",
    "print(\"HISTOGRAM CALCULATION AND VISUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def plot_histogram(img, title, ax):\n",
    "    \"\"\"Plot image and its histogram\"\"\"\n",
    "    # Calculate histogram\n",
    "    hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_val = np.mean(img)\n",
    "    std_val = np.std(img)\n",
    "    min_val = np.min(img)\n",
    "    max_val = np.max(img)\n",
    "    \n",
    "    # Plot histogram\n",
    "    ax.plot(hist, color='black', linewidth=1.5)\n",
    "    ax.fill_between(range(256), hist.flatten(), alpha=0.3, color='blue')\n",
    "    ax.set_xlim([0, 256])\n",
    "    ax.set_xlabel('Intensity')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{title}\\nμ={mean_val:.1f}, σ={std_val:.1f}, range=[{min_val},{max_val}]')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark mean\n",
    "    ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean={mean_val:.1f}')\n",
    "    ax.legend()\n",
    "    \n",
    "    return hist, mean_val, std_val\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "images_data = [\n",
    "    (img_dark, 'Dark Image'),\n",
    "    (img_bright, 'Bright Image'),\n",
    "    (img_low_contrast, 'Low Contrast'),\n",
    "    (img_normal, 'Normal Image')\n",
    "]\n",
    "\n",
    "print(f\"\\nImage statistics:\\n\")\n",
    "\n",
    "for i, (img, title) in enumerate(images_data):\n",
    "    # Show image\n",
    "    ax_img = plt.subplot(4, 2, 2*i + 1)\n",
    "    ax_img.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    ax_img.set_title(title)\n",
    "    ax_img.axis('off')\n",
    "    \n",
    "    # Show histogram\n",
    "    ax_hist = plt.subplot(4, 2, 2*i + 2)\n",
    "    hist, mean_val, std_val = plot_histogram(img, title, ax_hist)\n",
    "    \n",
    "    print(f\"{title}:\")\n",
    "    print(f\"  Mean: {mean_val:.2f}\")\n",
    "    print(f\"  Std Dev: {std_val:.2f}\")\n",
    "    print(f\"  Min: {img.min()}, Max: {img.max()}\")\n",
    "    print(f\"  Dynamic Range: {img.max() - img.min()}\")\n",
    "    print()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight: Histogram shape reveals image characteristics!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-color-hist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color histogram\n",
    "print(\"=\" * 70)\n",
    "print(\"COLOR HISTOGRAM (RGB)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load color image\n",
    "img_color = cv2.imread('normal.jpg')\n",
    "img_color_rgb = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Calculate histograms for each channel\n",
    "colors = ('r', 'g', 'b')\n",
    "channel_names = ('Red', 'Green', 'Blue')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Show original image\n",
    "axes[0, 0].imshow(img_color_rgb)\n",
    "axes[0, 0].set_title('Original Color Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Plot RGB histograms together\n",
    "for i, (color, name) in enumerate(zip(colors, channel_names)):\n",
    "    hist = cv2.calcHist([img_color], [i], None, [256], [0, 256])\n",
    "    axes[0, 1].plot(hist, color=color, linewidth=2, alpha=0.7, label=name)\n",
    "    axes[0, 1].set_xlim([0, 256])\n",
    "    axes[0, 1].set_xlabel('Intensity')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('RGB Histogram (Combined)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot individual channel histograms\n",
    "for i, (color, name) in enumerate(zip(colors, channel_names)):\n",
    "    hist = cv2.calcHist([img_color], [i], None, [256], [0, 256])\n",
    "    ax = axes[1, i] if i < 2 else axes[1, 1]\n",
    "    if i == 2:\n",
    "        ax.clear()\n",
    "    \n",
    "    row = 1\n",
    "    col = i\n",
    "    if i >= 2:\n",
    "        row = 1\n",
    "        col = 1\n",
    "        axes[1, 1].clear()\n",
    "    \n",
    "    axes[row, col].plot(hist, color=color, linewidth=2)\n",
    "    axes[row, col].fill_between(range(256), hist.flatten(), alpha=0.3, color=color)\n",
    "    axes[row, col].set_xlim([0, 256])\n",
    "    axes[row, col].set_xlabel('Intensity')\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "    axes[row, col].set_title(f'{name} Channel')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nColor statistics:\")\n",
    "for i, name in enumerate(channel_names):\n",
    "    channel_data = img_color[:, :, i]\n",
    "    print(f\"  {name}: mean={np.mean(channel_data):.2f}, std={np.std(channel_data):.2f}\")\n",
    "\n",
    "print(\"\\nKey Insight: Each RGB channel has its own histogram!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-equalization-theory",
   "metadata": {},
   "source": [
    "### 2. Histogram Equalization\n",
    "\n",
    "**Goal**: Enhance contrast by spreading out intensity distribution.\n",
    "\n",
    "#### Mathematical Foundation\n",
    "\n",
    "**Cumulative Distribution Function (CDF)**:\n",
    "$$\n",
    "c(i) = \\sum_{j=0}^{i} p(j)\n",
    "$$\n",
    "\n",
    "**Transformation function**:\n",
    "$$\n",
    "s = T(r) = (L-1) \\cdot c(r)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $r$: Input intensity level\n",
    "- $s$: Output intensity level  \n",
    "- $L$: Number of intensity levels (256 for 8-bit)\n",
    "\n",
    "**In discrete form**:\n",
    "$$\n",
    "s_k = (L-1) \\sum_{j=0}^{k} \\frac{n_j}{N} = \\frac{L-1}{N} \\sum_{j=0}^{k} n_j\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $n_j$: Number of pixels with intensity $j$\n",
    "- $N$: Total number of pixels\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "1. Calculate histogram $h(i)$\n",
    "2. Calculate normalized histogram $p(i) = h(i) / N$\n",
    "3. Calculate CDF: $c(i) = \\sum_{j=0}^{i} p(j)$\n",
    "4. Transform: $\\text{output}[i] = \\text{round}((L-1) \\cdot c[\\text{input}[i]])$\n",
    "\n",
    "#### Properties\n",
    "\n",
    "**Result**: Approximately uniform histogram (flat distribution)\n",
    "\n",
    "**Ideal output**:\n",
    "$$\n",
    "p_{\\text{ideal}}(i) = \\frac{1}{L} \\quad \\forall i\n",
    "$$\n",
    "\n",
    "**Advantages**:\n",
    "- Automatic (no parameters)\n",
    "- Enhances global contrast\n",
    "- Simple and fast\n",
    "\n",
    "**Disadvantages**:\n",
    "- May over-enhance noise\n",
    "- May change brightness\n",
    "- Global method (ignores local variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-equalization-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization\n",
    "print(\"=\" * 70)\n",
    "print(\"HISTOGRAM EQUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply histogram equalization\n",
    "img_eq = cv2.equalizeHist(img_dark)\n",
    "\n",
    "# Manual implementation for demonstration\n",
    "def manual_histogram_equalization(img):\n",
    "    \"\"\"Manual implementation of histogram equalization\"\"\"\n",
    "    # Calculate histogram\n",
    "    hist, _ = np.histogram(img.flatten(), bins=256, range=[0, 256])\n",
    "    \n",
    "    # Calculate CDF\n",
    "    cdf = hist.cumsum()\n",
    "    \n",
    "    # Normalize CDF to [0, 255]\n",
    "    cdf_normalized = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())\n",
    "    cdf_normalized = cdf_normalized.astype(np.uint8)\n",
    "    \n",
    "    # Apply transformation\n",
    "    img_eq_manual = cdf_normalized[img]\n",
    "    \n",
    "    return img_eq_manual, hist, cdf, cdf_normalized\n",
    "\n",
    "img_eq_manual, hist_orig, cdf_orig, cdf_norm = manual_histogram_equalization(img_dark)\n",
    "\n",
    "# Verify both methods give same result\n",
    "print(f\"\\nOpenCV and manual implementation match: {np.allclose(img_eq, img_eq_manual)}\")\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Original image\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "ax1.imshow(img_dark, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original Image (Dark)')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Original histogram\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "ax2.bar(range(256), hist_orig, color='blue', alpha=0.7)\n",
    "ax2.set_title(f'Original Histogram\\nMean={np.mean(img_dark):.1f}')\n",
    "ax2.set_xlabel('Intensity')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_xlim([0, 256])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# CDF\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "ax3.plot(cdf_orig, color='blue', linewidth=2, label='CDF')\n",
    "ax3.plot(cdf_norm, color='red', linewidth=2, linestyle='--', label='Normalized CDF')\n",
    "ax3.set_title('Cumulative Distribution Function')\n",
    "ax3.set_xlabel('Intensity')\n",
    "ax3.set_ylabel('Cumulative Count')\n",
    "ax3.set_xlim([0, 256])\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Equalized image\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "ax4.imshow(img_eq, cmap='gray', vmin=0, vmax=255)\n",
    "ax4.set_title('Equalized Image')\n",
    "ax4.axis('off')\n",
    "\n",
    "# Equalized histogram\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "hist_eq = cv2.calcHist([img_eq], [0], None, [256], [0, 256])\n",
    "ax5.bar(range(256), hist_eq.flatten(), color='green', alpha=0.7)\n",
    "ax5.set_title(f'Equalized Histogram\\nMean={np.mean(img_eq):.1f}')\n",
    "ax5.set_xlabel('Intensity')\n",
    "ax5.set_ylabel('Frequency')\n",
    "ax5.set_xlim([0, 256])\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Comparison\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "ax6.plot(hist_orig, color='blue', label='Original', alpha=0.7, linewidth=2)\n",
    "ax6.plot(hist_eq, color='green', label='Equalized', alpha=0.7, linewidth=2)\n",
    "ax6.set_title('Histogram Comparison')\n",
    "ax6.set_xlabel('Intensity')\n",
    "ax6.set_ylabel('Frequency')\n",
    "ax6.set_xlim([0, 256])\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Side by side comparison\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "comparison = np.hstack([img_dark, img_eq])\n",
    "ax7.imshow(comparison, cmap='gray')\n",
    "ax7.set_title('Before (Left) vs After (Right)')\n",
    "ax7.axis('off')\n",
    "\n",
    "# Transformation function visualization\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "ax8.plot(cdf_norm, color='purple', linewidth=2)\n",
    "ax8.plot([0, 255], [0, 255], 'k--', alpha=0.3, label='Identity')\n",
    "ax8.set_title('Transformation Function T(r)')\n",
    "ax8.set_xlabel('Input Intensity (r)')\n",
    "ax8.set_ylabel('Output Intensity (s)')\n",
    "ax8.set_xlim([0, 255])\n",
    "ax8.set_ylim([0, 255])\n",
    "ax8.legend()\n",
    "ax8.grid(True, alpha=0.3)\n",
    "ax8.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nContrast improvement:\")\n",
    "print(f\"  Original range: [{img_dark.min()}, {img_dark.max()}] = {img_dark.max() - img_dark.min()}\")\n",
    "print(f\"  Equalized range: [{img_eq.min()}, {img_eq.max()}] = {img_eq.max() - img_eq.min()}\")\n",
    "print(f\"  Original std: {np.std(img_dark):.2f}\")\n",
    "print(f\"  Equalized std: {np.std(img_eq):.2f}\")\n",
    "\n",
    "print(\"\\nKey Insight: Equalization spreads out intensities for better contrast!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-clahe-theory",
   "metadata": {},
   "source": [
    "### 3. Adaptive Histogram Equalization (CLAHE)\n",
    "\n",
    "**CLAHE** = Contrast Limited Adaptive Histogram Equalization\n",
    "\n",
    "#### Problems with Global Equalization\n",
    "\n",
    "1. **Over-enhancement**: Amplifies noise\n",
    "2. **Ignores local contrast**: Uses global statistics\n",
    "3. **Artifacts**: Creates unnatural appearance\n",
    "\n",
    "#### CLAHE Solution\n",
    "\n",
    "**Adaptive**: Divide image into tiles, equalize each separately\n",
    "\n",
    "**Contrast limiting**: Clip histogram to prevent over-amplification\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "1. **Divide** image into $M \\times N$ tiles (e.g., 8×8)\n",
    "2. For each tile:\n",
    "   - Calculate histogram $h(i)$\n",
    "   - **Clip** histogram at threshold:\n",
    "     $$\n",
    "     h_{\\text{clipped}}(i) = \\min(h(i), \\text{clipLimit})\n",
    "     $$\n",
    "   - Redistribute excess pixels uniformly\n",
    "   - Compute equalization\n",
    "3. **Interpolate** between tiles (bilinear) to avoid boundary artifacts\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "**clipLimit**: Contrast limiting threshold\n",
    "- Higher → more contrast enhancement\n",
    "- Lower → less enhancement, more natural\n",
    "- Typical: 2.0 - 4.0\n",
    "\n",
    "**tileGridSize**: Size of tiles\n",
    "- Smaller tiles → more local adaptation\n",
    "- Larger tiles → more global (closer to standard equalization)\n",
    "- Typical: (8, 8)\n",
    "\n",
    "#### CLAHE vs Standard Equalization\n",
    "\n",
    "| Property | Standard | CLAHE |\n",
    "|----------|----------|-------|\n",
    "| Scope | Global | Local (tiles) |\n",
    "| Noise | Amplifies | **Limits** |\n",
    "| Contrast | High (may be excessive) | **Controlled** |\n",
    "| Appearance | May be unnatural | **More natural** |\n",
    "| Speed | Fast | Slower |\n",
    "| Use case | Simple images | **Complex images** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-clahe-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "print(\"=\" * 70)\n",
    "print(\"CLAHE - ADAPTIVE HISTOGRAM EQUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create CLAHE object\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "img_clahe = clahe.apply(img_dark)\n",
    "\n",
    "# Compare different clipLimits\n",
    "clip_limits = [1.0, 2.0, 4.0, 8.0]\n",
    "clahe_results = []\n",
    "\n",
    "print(f\"\\nTesting different clipLimit values:\\n\")\n",
    "\n",
    "for clip_limit in clip_limits:\n",
    "    clahe_temp = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    result = clahe_temp.apply(img_dark)\n",
    "    clahe_results.append(result)\n",
    "    print(f\"clipLimit={clip_limit}: std={np.std(result):.2f}\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(img_dark, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 0].set_title('Original (Dark)')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Standard equalization\n",
    "axes[0, 1].imshow(img_eq, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 1].set_title('Standard Equalization')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# CLAHE (default)\n",
    "axes[0, 2].imshow(img_clahe, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 2].set_title('CLAHE (clipLimit=2.0)')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Histograms\n",
    "hist_dark = cv2.calcHist([img_dark], [0], None, [256], [0, 256])\n",
    "hist_eq = cv2.calcHist([img_eq], [0], None, [256], [0, 256])\n",
    "hist_clahe = cv2.calcHist([img_clahe], [0], None, [256], [0, 256])\n",
    "\n",
    "axes[1, 0].plot(hist_dark, color='blue', linewidth=2)\n",
    "axes[1, 0].set_title('Original Histogram')\n",
    "axes[1, 0].set_xlim([0, 256])\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(hist_eq, color='green', linewidth=2)\n",
    "axes[1, 1].set_title('Standard Equalization Histogram')\n",
    "axes[1, 1].set_xlim([0, 256])\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 2].plot(hist_clahe, color='red', linewidth=2)\n",
    "axes[1, 2].set_title('CLAHE Histogram')\n",
    "axes[1, 2].set_xlim([0, 256])\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Different clipLimits\n",
    "for i, (clip_limit, result) in enumerate(zip(clip_limits[:3], clahe_results[:3])):\n",
    "    axes[2, i].imshow(result, cmap='gray', vmin=0, vmax=255)\n",
    "    axes[2, i].set_title(f'CLAHE clipLimit={clip_limit}')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detail comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Crop a region for detail\n",
    "h, w = img_dark.shape\n",
    "crop = (slice(h//4, 3*h//4), slice(w//4, 3*w//4))\n",
    "\n",
    "axes[0].imshow(img_dark[crop], cmap='gray')\n",
    "axes[0].set_title('Original (Detail)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(img_eq[crop], cmap='gray')\n",
    "axes[1].set_title('Standard Equalization (Detail)\\nNote: May amplify noise')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(img_clahe[crop], cmap='gray')\n",
    "axes[2].set_title('CLAHE (Detail)\\nNote: More natural appearance')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: CLAHE provides better local contrast with less noise!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-color-eq",
   "metadata": {},
   "source": [
    "### 4. Color Image Equalization\n",
    "\n",
    "**Problem**: Cannot directly equalize RGB channels!\n",
    "\n",
    "**Why?** Equalizing R, G, B independently changes color balance.\n",
    "\n",
    "#### Solution 1: Convert to HSV\n",
    "\n",
    "1. Convert RGB → HSV\n",
    "2. Equalize **V (Value)** channel only\n",
    "3. Convert back: HSV → RGB\n",
    "\n",
    "**Preserves**: Hue and Saturation (color information)\n",
    "\n",
    "**Enhances**: Brightness/Intensity\n",
    "\n",
    "#### Solution 2: Convert to YCrCb\n",
    "\n",
    "1. Convert RGB → YCrCb\n",
    "2. Equalize **Y (Luminance)** channel only\n",
    "3. Convert back: YCrCb → RGB\n",
    "\n",
    "**YCrCb** separates:\n",
    "- Y: Luminance (brightness)\n",
    "- Cr, Cb: Chrominance (color)\n",
    "\n",
    "#### Solution 3: Convert to LAB\n",
    "\n",
    "1. Convert RGB → LAB\n",
    "2. Equalize **L (Lightness)** channel only\n",
    "3. Convert back: LAB → RGB\n",
    "\n",
    "**LAB** is perceptually uniform:\n",
    "- L: Lightness\n",
    "- A: Green-Red\n",
    "- B: Blue-Yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-color-eq-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color image equalization\n",
    "print(\"=\" * 70)\n",
    "print(\"COLOR IMAGE EQUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load color image (make it darker for demonstration)\n",
    "img_color_dark = (img_color * 0.5).astype(np.uint8)\n",
    "img_color_dark_rgb = cv2.cvtColor(img_color_dark, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Method 1: Wrong way (equalize each RGB channel)\n",
    "img_rgb_eq = img_color_dark.copy()\n",
    "for i in range(3):\n",
    "    img_rgb_eq[:, :, i] = cv2.equalizeHist(img_color_dark[:, :, i])\n",
    "img_rgb_eq_rgb = cv2.cvtColor(img_rgb_eq, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Method 2: HSV (equalize V channel)\n",
    "img_hsv = cv2.cvtColor(img_color_dark, cv2.COLOR_BGR2HSV)\n",
    "img_hsv[:, :, 2] = cv2.equalizeHist(img_hsv[:, :, 2])\n",
    "img_hsv_eq = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "img_hsv_eq_rgb = cv2.cvtColor(img_hsv_eq, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Method 3: YCrCb (equalize Y channel)\n",
    "img_ycrcb = cv2.cvtColor(img_color_dark, cv2.COLOR_BGR2YCrCb)\n",
    "img_ycrcb[:, :, 0] = cv2.equalizeHist(img_ycrcb[:, :, 0])\n",
    "img_ycrcb_eq = cv2.cvtColor(img_ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "img_ycrcb_eq_rgb = cv2.cvtColor(img_ycrcb_eq, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Method 4: LAB (equalize L channel)\n",
    "img_lab = cv2.cvtColor(img_color_dark, cv2.COLOR_BGR2LAB)\n",
    "img_lab[:, :, 0] = cv2.equalizeHist(img_lab[:, :, 0])\n",
    "img_lab_eq = cv2.cvtColor(img_lab, cv2.COLOR_LAB2BGR)\n",
    "img_lab_eq_rgb = cv2.cvtColor(img_lab_eq, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Method 5: CLAHE on LAB\n",
    "img_lab_clahe = cv2.cvtColor(img_color_dark, cv2.COLOR_BGR2LAB)\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "img_lab_clahe[:, :, 0] = clahe.apply(img_lab_clahe[:, :, 0])\n",
    "img_lab_clahe_result = cv2.cvtColor(img_lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "img_lab_clahe_rgb = cv2.cvtColor(img_lab_clahe_result, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 11))\n",
    "\n",
    "axes[0, 0].imshow(img_color_dark_rgb)\n",
    "axes[0, 0].set_title('Original (Dark)')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(img_rgb_eq_rgb)\n",
    "axes[0, 1].set_title('RGB Channels Equalized\\n⚠️ WRONG: Color shift!')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(img_hsv_eq_rgb)\n",
    "axes[0, 2].set_title('HSV (V channel)\\n✓ Preserves color')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(img_ycrcb_eq_rgb)\n",
    "axes[1, 0].set_title('YCrCb (Y channel)\\n✓ Good separation')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(img_lab_eq_rgb)\n",
    "axes[1, 1].set_title('LAB (L channel)\\n✓ Perceptually uniform')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(img_lab_clahe_rgb)\n",
    "axes[1, 2].set_title('LAB + CLAHE\\n✓✓ BEST: Natural enhancement')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"  ❌ Never equalize RGB channels independently\")\n",
    "print(\"  ✓ HSV: Simple, preserves hue\")\n",
    "print(\"  ✓ YCrCb: Good for video\")\n",
    "print(\"  ✓ LAB: Perceptually uniform\")\n",
    "print(\"  ✓✓ LAB + CLAHE: Best for most applications\")\n",
    "\n",
    "print(\"\\nKey Insight: Use color spaces that separate luminance from chrominance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Histogram**: Statistical representation of intensity distribution\n",
    "2. **Histogram Equalization**: Enhance contrast by spreading intensities\n",
    "3. **CLAHE**: Adaptive equalization with contrast limiting\n",
    "4. **Color Equalization**: Separate luminance from chrominance\n",
    "\n",
    "### Mathematical Formulas Reference\n",
    "\n",
    "**Histogram**:\n",
    "$$\n",
    "h(i) = \\text{count of pixels with intensity } i\n",
    "$$\n",
    "\n",
    "**Normalized histogram**:\n",
    "$$\n",
    "p(i) = \\frac{h(i)}{N}\n",
    "$$\n",
    "\n",
    "**CDF**:\n",
    "$$\n",
    "c(i) = \\sum_{j=0}^{i} p(j)\n",
    "$$\n",
    "\n",
    "**Equalization transformation**:\n",
    "$$\n",
    "s = T(r) = (L-1) \\cdot c(r)\n",
    "$$\n",
    "\n",
    "**Mean**:\n",
    "$$\n",
    "\\mu = \\sum_{i=0}^{L-1} i \\cdot p(i)\n",
    "$$\n",
    "\n",
    "**Variance**:\n",
    "$$\n",
    "\\sigma^2 = \\sum_{i=0}^{L-1} (i-\\mu)^2 \\cdot p(i)\n",
    "$$\n",
    "\n",
    "### Method Comparison\n",
    "\n",
    "| Method | Scope | Noise | Best For |\n",
    "|--------|-------|-------|----------|\n",
    "| **Standard Equalization** | Global | Amplifies | Simple, low-noise images |\n",
    "| **CLAHE** | Local | **Limits** | Complex images, medical imaging |\n",
    "| **HSV Equalization** | V channel | Varies | Color photos (preserves hue) |\n",
    "| **YCrCb Equalization** | Y channel | Varies | Video processing |\n",
    "| **LAB + CLAHE** | L channel | **Limits** | **Best overall** |\n",
    "\n",
    "### OpenCV Functions Reference\n",
    "\n",
    "| Operation | Function | Key Parameters |\n",
    "|-----------|----------|----------------|\n",
    "| Calculate histogram | `cv2.calcHist([img], [0], None, [256], [0,256])` | channels, bins, range |\n",
    "| Equalize | `cv2.equalizeHist(img)` | Grayscale only |\n",
    "| Create CLAHE | `cv2.createCLAHE(clipLimit, tileGridSize)` | clipLimit ≈ 2.0 |\n",
    "| Apply CLAHE | `clahe.apply(img)` | Returns equalized image |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Grayscale**: Use standard equalization or CLAHE directly\n",
    "2. **Color**: Convert to HSV/YCrCb/LAB, equalize intensity channel only\n",
    "3. **Noisy images**: Use CLAHE (lower clipLimit)\n",
    "4. **Medical images**: CLAHE with small tiles\n",
    "5. **Natural photos**: LAB + CLAHE (clipLimit ≈ 2.0-3.0)\n",
    "\n",
    "**Next**: Module 9 - Image Segmentation"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}