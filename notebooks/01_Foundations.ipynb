{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Foundations\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/computer-graphics/blob/main/notebooks/01_Foundations.ipynb)\n",
    "\n",
    "**Week 1-2: Image Representation & Basic Operations**\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand image representation as NumPy arrays\n",
    "- Load, display, and save images\n",
    "- Manipulate pixels and regions of interest (ROI)\n",
    "- Work with image properties and color channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenCV in Google Colab (uncomment if using Colab)\n",
    "# !pip install opencv-python opencv-contrib-python\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab.patches import cv2_imshow  # Use this in Colab instead of cv2.imshow\n",
    "\n",
    "# For better plot quality\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-matrix-intro",
   "metadata": {},
   "source": [
    "## Understanding Images as Matrices\n",
    "\n",
    "Before we start, let's understand the fundamental concept: **Images are just matrices (multi-dimensional arrays)**.\n",
    "\n",
    "**Key Concepts**:\n",
    "- A **grayscale image** is a 2D matrix: `height x width`\n",
    "- A **color image** is a 3D matrix: `height x width x channels`\n",
    "- Each element in the matrix is a pixel value (usually 0-255 for 8-bit images)\n",
    "\n",
    "This means we can use **matrix operations** to process images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-matrix-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize a tiny image as a matrix\n",
    "tiny_img = np.array([\n",
    "    [0, 50, 100],\n",
    "    [150, 200, 250],\n",
    "    [100, 150, 200]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "print(\"Tiny 3x3 grayscale image as a matrix:\")\n",
    "print(tiny_img)\n",
    "print(f\"\\nShape: {tiny_img.shape}\")\n",
    "print(f\"Size: {tiny_img.size} pixels\")\n",
    "\n",
    "# Visualize it\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Show as matrix values\n",
    "axes[0].text(0.5, 0.5, str(tiny_img), \n",
    "             ha='center', va='center', \n",
    "             fontfamily='monospace', fontsize=14)\n",
    "axes[0].set_title('Matrix Representation')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Show as image\n",
    "axes[1].imshow(tiny_img, cmap='gray', vmin=0, vmax=255)\n",
    "axes[1].set_title('Image Representation')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Add pixel values as text overlay\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axes[1].text(j, i, str(tiny_img[i, j]), \n",
    "                    ha='center', va='center', \n",
    "                    color='red', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: Each number in the matrix represents a pixel brightness!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-math-theory-intro",
   "metadata": {},
   "source": [
    "---\n",
    "## Mathematical Foundations: Matrix Theory for Image Processing\n",
    "\n",
    "Before diving deeper, let's establish the **theoretical mathematical basis** for matrix operations in image processing.\n",
    "\n",
    "### Why Matrix Theory Matters\n",
    "\n",
    "Images are fundamentally **matrices**, and image processing operations are **matrix operations**. Understanding the underlying mathematics allows you to:\n",
    "- Predict the outcome of operations\n",
    "- Design custom filters and transformations\n",
    "- Optimize performance\n",
    "- Understand advanced techniques (convolution, SVD, PCA, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-matrix-def",
   "metadata": {},
   "source": [
    "### 1. Matrix Definitions and Notation\n",
    "\n",
    "#### Definition: Matrix\n",
    "A **matrix** is a rectangular array of numbers arranged in rows and columns.\n",
    "\n",
    "**General form** ($m \\times n$ matrix):\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $m$ = number of rows (height in images)\n",
    "- $n$ = number of columns (width in images)\n",
    "- $a_{ij}$ = element at row $i$, column $j$\n",
    "\n",
    "**Image interpretation**:\n",
    "- **Grayscale image**: $m \\times n$ matrix where $a_{ij} \\in [0, 255]$\n",
    "- **Color image**: $m \\times n \\times 3$ tensor (3D array) where each \"slice\" is a 2D matrix\n",
    "\n",
    "#### Special Matrices\n",
    "\n",
    "1. **Zero Matrix** ($\\mathbf{O}$): All elements are 0\n",
    "   $$\n",
    "   \\mathbf{O} = \\begin{bmatrix}\n",
    "   0 & 0 & 0 \\\\\n",
    "   0 & 0 & 0\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "   Image: Black image\n",
    "\n",
    "2. **Ones Matrix** ($\\mathbf{J}$): All elements are 1\n",
    "   $$\n",
    "   \\mathbf{J} = \\begin{bmatrix}\n",
    "   1 & 1 & 1 \\\\\n",
    "   1 & 1 & 1\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "3. **Identity Matrix** ($\\mathbf{I}$): Diagonal elements are 1, others are 0\n",
    "   $$\n",
    "   \\mathbf{I} = \\begin{bmatrix}\n",
    "   1 & 0 & 0 \\\\\n",
    "   0 & 1 & 0 \\\\\n",
    "   0 & 0 & 1\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "   Property: $A \\times \\mathbf{I} = A$ (identity for matrix multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-matrix-types-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate special matrices\n",
    "print(\"=\" * 70)\n",
    "print(\"SPECIAL MATRICES IN IMAGE PROCESSING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Zero matrix (black image)\n",
    "zero_matrix = np.zeros((4, 5), dtype=np.uint8)\n",
    "print(\"\\nZero Matrix O (4×5):\")\n",
    "print(zero_matrix)\n",
    "print(\"Image interpretation: Black image\")\n",
    "\n",
    "# Ones matrix\n",
    "ones_matrix = np.ones((4, 5), dtype=np.uint8)\n",
    "print(\"\\nOnes Matrix J (4×5):\")\n",
    "print(ones_matrix)\n",
    "print(\"Image interpretation: Very dark image (value 1)\")\n",
    "\n",
    "# Scaled ones matrix (white image)\n",
    "white_matrix = np.ones((4, 5), dtype=np.uint8) * 255\n",
    "print(\"\\nScaled Ones Matrix 255×J (4×5):\")\n",
    "print(white_matrix)\n",
    "print(\"Image interpretation: White image\")\n",
    "\n",
    "# Identity matrix\n",
    "identity_matrix = np.eye(4, dtype=np.uint8)\n",
    "print(\"\\nIdentity Matrix I (4×4):\")\n",
    "print(identity_matrix)\n",
    "print(\"Image interpretation: Diagonal white line on black background\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(zero_matrix, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0].set_title('Zero Matrix O\\n(Black)', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(ones_matrix, cmap='gray', vmin=0, vmax=255)\n",
    "axes[1].set_title('Ones Matrix J\\n(Very Dark)', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(white_matrix, cmap='gray', vmin=0, vmax=255)\n",
    "axes[2].set_title('255×J\\n(White)', fontsize=12)\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(identity_matrix, cmap='gray', vmin=0, vmax=255)\n",
    "axes[3].set_title('Identity Matrix I\\n(Diagonal)', fontsize=12)\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-elementwise-theory",
   "metadata": {},
   "source": [
    "### 2. Element-wise Operations (Hadamard Operations)\n",
    "\n",
    "Most image operations are **element-wise** (not standard matrix multiplication!).\n",
    "\n",
    "#### Addition\n",
    "**Definition**: Given matrices $A$ and $B$ of same dimensions $m \\times n$:\n",
    "\n",
    "$$\n",
    "(A + B)_{ij} = a_{ij} + b_{ij}\n",
    "$$\n",
    "\n",
    "**Properties**:\n",
    "- **Commutative**: $A + B = B + A$\n",
    "- **Associative**: $(A + B) + C = A + (B + C)$\n",
    "- **Identity**: $A + \\mathbf{O} = A$ (zero matrix is additive identity)\n",
    "- **Inverse**: $A + (-A) = \\mathbf{O}$\n",
    "\n",
    "**Image interpretation**: Brighten image by adding constant matrix\n",
    "\n",
    "#### Scalar Multiplication\n",
    "**Definition**: Given matrix $A$ and scalar $c \\in \\mathbb{R}$:\n",
    "\n",
    "$$\n",
    "(c \\cdot A)_{ij} = c \\cdot a_{ij}\n",
    "$$\n",
    "\n",
    "**Properties**:\n",
    "- **Distributive over matrix addition**: $c(A + B) = cA + cB$\n",
    "- **Distributive over scalar addition**: $(c + d)A = cA + dA$\n",
    "- **Associative**: $c(dA) = (cd)A$\n",
    "- **Identity**: $1 \\cdot A = A$\n",
    "\n",
    "**Image interpretation**: Adjust brightness/contrast\n",
    "\n",
    "#### Hadamard Product (Element-wise Multiplication)\n",
    "**Definition**: Given matrices $A$ and $B$ of same dimensions:\n",
    "\n",
    "$$\n",
    "(A \\odot B)_{ij} = a_{ij} \\cdot b_{ij}\n",
    "$$\n",
    "\n",
    "**Symbol**: $\\odot$ (not standard matrix multiplication $\\times$!)\n",
    "\n",
    "**Properties**:\n",
    "- **Commutative**: $A \\odot B = B \\odot A$\n",
    "- **Associative**: $(A \\odot B) \\odot C = A \\odot (B \\odot C)$\n",
    "- **Distributive**: $A \\odot (B + C) = (A \\odot B) + (A \\odot C)$\n",
    "\n",
    "**Image interpretation**: Masking (multiply by binary mask to select regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-elementwise-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate element-wise operations mathematically\n",
    "print(\"=\" * 70)\n",
    "print(\"ELEMENT-WISE OPERATIONS: THEORY AND PRACTICE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define two small matrices\n",
    "A = np.array([[10, 20, 30],\n",
    "              [40, 50, 60]], dtype=np.uint8)\n",
    "\n",
    "B = np.array([[5, 10, 15],\n",
    "              [20, 25, 30]], dtype=np.uint8)\n",
    "\n",
    "print(\"\\nMatrix A:\")\n",
    "print(A)\n",
    "print(\"\\nMatrix B:\")\n",
    "print(B)\n",
    "\n",
    "# Addition\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ADDITION: (A + B)ᵢⱼ = aᵢⱼ + bᵢⱼ\")\n",
    "print(\"=\"*70)\n",
    "C_add = A + B\n",
    "print(\"A + B:\")\n",
    "print(C_add)\n",
    "print(f\"\\nVerify commutativity (A + B = B + A): {np.array_equal(A + B, B + A)}\")\n",
    "print(f\"Verify identity (A + O = A): {np.array_equal(A + np.zeros_like(A), A)}\")\n",
    "\n",
    "# Scalar multiplication\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCALAR MULTIPLICATION: (c·A)ᵢⱼ = c·aᵢⱼ\")\n",
    "print(\"=\"*70)\n",
    "c = 2\n",
    "C_scalar = c * A\n",
    "print(f\"{c}·A:\")\n",
    "print(C_scalar)\n",
    "print(f\"\\nVerify distributivity c(A+B) = cA + cB:\")\n",
    "print(f\"  c(A+B) = {c}×({A[0,0]}+{B[0,0]}) = {c*(A[0,0]+B[0,0])}\")\n",
    "print(f\"  cA+cB = {c}×{A[0,0]} + {c}×{B[0,0]} = {c*A[0,0] + c*B[0,0]}\")\n",
    "print(f\"  Equal: {np.array_equal(c*(A+B), c*A + c*B)}\")\n",
    "\n",
    "# Hadamard product\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HADAMARD PRODUCT: (A ⊙ B)ᵢⱼ = aᵢⱼ · bᵢⱼ\")\n",
    "print(\"=\"*70)\n",
    "C_hadamard = A * B  # Element-wise in NumPy\n",
    "print(\"A ⊙ B:\")\n",
    "print(C_hadamard)\n",
    "print(f\"\\nVerify commutativity (A⊙B = B⊙A): {np.array_equal(A*B, B*A)}\")\n",
    "print(f\"Example: a₁₁ × b₁₁ = {A[0,0]} × {B[0,0]} = {A[0,0] * B[0,0]}\")\n",
    "\n",
    "# Visualize operations on images\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUAL DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create test images\n",
    "img1 = np.full((100, 100), 100, dtype=np.uint8)\n",
    "img2 = np.full((100, 100), 50, dtype=np.uint8)\n",
    "\n",
    "# Operations\n",
    "result_add = cv2.add(img1, img2)\n",
    "result_scalar = cv2.multiply(img1, np.array([2.0]))\n",
    "result_hadamard = cv2.multiply(img1, img2, scale=1/255.0)  # Normalized\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(img1, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 0].set_title('A (constant 100)', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(img2, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 1].set_title('B (constant 50)', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(result_add, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 2].set_title('A + B = 150', fontsize=12)\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(result_scalar, cmap='gray', vmin=0, vmax=255)\n",
    "axes[1, 0].set_title('2·A = 200', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(result_hadamard, cmap='gray', vmin=0, vmax=255)\n",
    "axes[1, 1].set_title('A⊙B/255 ≈ 20', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTheoretical values:\")\n",
    "print(f\"  A + B = {img1[0,0]} + {img2[0,0]} = {img1[0,0] + img2[0,0]}\")\n",
    "print(f\"  2·A = 2 × {img1[0,0]} = {2 * img1[0,0]}\")\n",
    "print(f\"  A⊙B/255 = ({img1[0,0]} × {img2[0,0]})/255 ≈ {(img1[0,0] * img2[0,0])//255}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-linear-combo-theory",
   "metadata": {},
   "source": [
    "### 3. Linear Combinations and Affine Transformations\n",
    "\n",
    "#### Linear Combination\n",
    "**Definition**: A linear combination of matrices $A_1, A_2, \\ldots, A_n$ with scalars $c_1, c_2, \\ldots, c_n$ is:\n",
    "\n",
    "$$\n",
    "C = c_1 A_1 + c_2 A_2 + \\cdots + c_n A_n = \\sum_{k=1}^{n} c_k A_k\n",
    "$$\n",
    "\n",
    "**Properties**:\n",
    "- Forms a **vector space** (set of all linear combinations)\n",
    "- **Closure**: Linear combinations of matrices produce matrices\n",
    "- **Basis**: Any matrix can be expressed as linear combination of basis matrices\n",
    "\n",
    "**Image applications**:\n",
    "1. **Image blending**: $C = \\alpha A + (1-\\alpha)B$ where $\\alpha \\in [0,1]$\n",
    "2. **Alpha compositing**: $\\text{Composite} = \\alpha \\cdot \\text{Foreground} + (1-\\alpha) \\cdot \\text{Background}$\n",
    "3. **Color correction**: $\\text{Output} = c_1 \\cdot \\text{Red} + c_2 \\cdot \\text{Green} + c_3 \\cdot \\text{Blue}$\n",
    "\n",
    "#### Affine Transformation\n",
    "**Definition**: An affine transformation combines linear transformation and translation:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = A\\mathbf{x} + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $A$: Linear transformation matrix (rotation, scaling, shear)\n",
    "- $\\mathbf{b}$: Translation vector\n",
    "- $\\mathbf{x}$: Input vector (pixel coordinates)\n",
    "\n",
    "**Image interpretation**: Brightness/contrast adjustment\n",
    "\n",
    "$$\n",
    "\\text{Output} = \\alpha \\cdot \\text{Input} + \\beta\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha$: Contrast gain (slope)\n",
    "- $\\beta$: Brightness offset (intercept)\n",
    "\n",
    "**Transfer function**: Maps input pixel values to output values\n",
    "$$\n",
    "g(x, y) = \\alpha \\cdot f(x, y) + \\beta\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-linear-combo-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate linear combinations and affine transformations\n",
    "print(\"=\" * 70)\n",
    "print(\"LINEAR COMBINATIONS: THEORY AND APPLICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create two base images\n",
    "img_a = np.array([[0, 50, 100],\n",
    "                  [150, 200, 250]], dtype=np.uint8)\n",
    "\n",
    "img_b = np.array([[250, 200, 150],\n",
    "                  [100, 50, 0]], dtype=np.uint8)\n",
    "\n",
    "print(\"\\nBase images:\")\n",
    "print(\"Image A:\")\n",
    "print(img_a)\n",
    "print(\"\\nImage B:\")\n",
    "print(img_b)\n",
    "\n",
    "# Linear combination: C = αA + βB\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LINEAR COMBINATION: C = αA + βB\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "alphas = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "for alpha in alphas:\n",
    "    beta = 1.0 - alpha\n",
    "    # Convert to float for computation, then clip and convert back\n",
    "    C = np.clip(alpha * img_a.astype(float) + beta * img_b.astype(float), 0, 255).astype(np.uint8)\n",
    "    print(f\"\\nα={alpha:.2f}, β={beta:.2f}:\")\n",
    "    print(f\"  C[0,0] = {alpha:.2f}×{img_a[0,0]} + {beta:.2f}×{img_b[0,0]} = {C[0,0]}\")\n",
    "    print(f\"  C[0,2] = {alpha:.2f}×{img_a[0,2]} + {beta:.2f}×{img_b[0,2]} = {C[0,2]}\")\n",
    "\n",
    "# Affine transformation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AFFINE TRANSFORMATION: Output = α·Input + β\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "alpha_affine = 1.5  # Contrast gain\n",
    "beta_affine = 30    # Brightness offset\n",
    "\n",
    "# Create sample image\n",
    "input_img = np.array([[0, 50, 100],\n",
    "                      [150, 200, 250]], dtype=np.uint8)\n",
    "\n",
    "# Apply affine transformation with saturation\n",
    "output_img = np.clip(alpha_affine * input_img.astype(float) + beta_affine, 0, 255).astype(np.uint8)\n",
    "\n",
    "print(f\"\\nα (contrast) = {alpha_affine}\")\n",
    "print(f\"β (brightness) = {beta_affine}\")\n",
    "print(\"\\nInput:\")\n",
    "print(input_img)\n",
    "print(\"\\nOutput = α·Input + β:\")\n",
    "print(output_img)\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"  Output[0,1] = {alpha_affine}×{input_img[0,1]} + {beta_affine} = {alpha_affine*input_img[0,1] + beta_affine} → {output_img[0,1]} (clipped)\")\n",
    "print(f\"  Output[1,2] = {alpha_affine}×{input_img[1,2]} + {beta_affine} = {alpha_affine*input_img[1,2] + beta_affine} → {output_img[1,2]} (clipped to 255)\")\n",
    "\n",
    "# Visual demonstration\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUAL DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create gradient images for better visualization\n",
    "grad1 = np.linspace(0, 255, 100).reshape(1, 100).repeat(100, axis=0).astype(np.uint8)\n",
    "grad2 = np.linspace(255, 0, 100).reshape(1, 100).repeat(100, axis=0).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Linear combination demonstration\n",
    "axes[0, 0].imshow(grad1, cmap='gray')\n",
    "axes[0, 0].set_title('Image A\\n(0→255)', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(grad2, cmap='gray')\n",
    "axes[0, 1].set_title('Image B\\n(255→0)', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "blend = cv2.addWeighted(grad1, 0.5, grad2, 0.5, 0)\n",
    "axes[0, 2].imshow(blend, cmap='gray')\n",
    "axes[0, 2].set_title('Linear Combo\\n0.5A + 0.5B', fontsize=12)\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Affine transformation demonstration\n",
    "axes[1, 0].imshow(grad1, cmap='gray')\n",
    "axes[1, 0].set_title('Input', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "affine1 = np.clip(1.5 * grad1.astype(float), 0, 255).astype(np.uint8)\n",
    "axes[1, 1].imshow(affine1, cmap='gray')\n",
    "axes[1, 1].set_title('1.5×Input\\n(High Contrast)', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "affine2 = np.clip(1.2 * grad1.astype(float) + 50, 0, 255).astype(np.uint8)\n",
    "axes[1, 2].imshow(affine2, cmap='gray')\n",
    "axes[1, 2].set_title('1.2×Input + 50\\n(Contrast + Bright)', fontsize=12)\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: Image blending is a linear combination!\")\n",
    "print(\"Key Insight: Brightness/contrast adjustment is an affine transformation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-matrix-norms-theory",
   "metadata": {},
   "source": [
    "### 4. Matrix Norms and Distance Metrics\n",
    "\n",
    "#### Matrix Norms\n",
    "A **norm** measures the \"size\" or \"magnitude\" of a matrix.\n",
    "\n",
    "**Frobenius Norm** (most common for images):\n",
    "\n",
    "$$\n",
    "\\|A\\|_F = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij}|^2}\n",
    "$$\n",
    "\n",
    "**Properties**:\n",
    "- **Non-negative**: $\\|A\\| \\geq 0$\n",
    "- **Zero**: $\\|A\\| = 0 \\iff A = \\mathbf{O}$\n",
    "- **Triangle inequality**: $\\|A + B\\| \\leq \\|A\\| + \\|B\\|$\n",
    "- **Scalar multiplication**: $\\|cA\\| = |c| \\cdot \\|A\\|$\n",
    "\n",
    "**Image interpretation**: Total energy/intensity in an image\n",
    "\n",
    "#### Distance Metrics\n",
    "Measure similarity/difference between two images $A$ and $B$:\n",
    "\n",
    "1. **Euclidean Distance** ($L^2$ distance):\n",
    "   $$\n",
    "   d_2(A, B) = \\|A - B\\|_F = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} (a_{ij} - b_{ij})^2}\n",
    "   $$\n",
    "   Use: Image similarity, template matching\n",
    "\n",
    "2. **Manhattan Distance** ($L^1$ distance):\n",
    "   $$\n",
    "   d_1(A, B) = \\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij} - b_{ij}|\n",
    "   $$\n",
    "   Use: Faster computation, less sensitive to outliers\n",
    "\n",
    "3. **Maximum Norm** ($L^\\infty$ distance):\n",
    "   $$\n",
    "   d_\\infty(A, B) = \\max_{i,j} |a_{ij} - b_{ij}|\n",
    "   $$\n",
    "   Use: Worst-case pixel difference\n",
    "\n",
    "#### Mean Squared Error (MSE)\n",
    "**Definition**:\n",
    "\n",
    "$$\n",
    "\\text{MSE}(A, B) = \\frac{1}{mn} \\sum_{i=1}^{m} \\sum_{j=1}^{n} (a_{ij} - b_{ij})^2\n",
    "$$\n",
    "\n",
    "**Relationship to Frobenius norm**:\n",
    "$$\n",
    "\\text{MSE}(A, B) = \\frac{\\|A - B\\|_F^2}{mn}\n",
    "$$\n",
    "\n",
    "**Peak Signal-to-Noise Ratio (PSNR)**:\n",
    "$$\n",
    "\\text{PSNR} = 10 \\log_{10}\\left(\\frac{\\text{MAX}^2}{\\text{MSE}}\\right) \\text{ dB}\n",
    "$$\n",
    "\n",
    "Where $\\text{MAX} = 255$ for 8-bit images.\n",
    "\n",
    "**Image interpretation**: Average squared pixel difference (quality metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-norms-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate matrix norms and distance metrics\n",
    "print(\"=\" * 70)\n",
    "print(\"MATRIX NORMS AND DISTANCE METRICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create test matrices\n",
    "A = np.array([[3, 4],\n",
    "              [0, 5]], dtype=np.float32)\n",
    "\n",
    "B = np.array([[1, 2],\n",
    "              [3, 4]], dtype=np.float32)\n",
    "\n",
    "print(\"\\nMatrix A:\")\n",
    "print(A)\n",
    "print(\"\\nMatrix B:\")\n",
    "print(B)\n",
    "\n",
    "# Frobenius norm\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FROBENIUS NORM: ||A||_F = √(Σᵢ Σⱼ aᵢⱼ²)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "norm_A = np.linalg.norm(A, 'fro')\n",
    "manual_norm_A = np.sqrt(np.sum(A**2))\n",
    "\n",
    "print(f\"||A||_F = √(3² + 4² + 0² + 5²) = √{3**2 + 4**2 + 0**2 + 5**2} = {norm_A:.2f}\")\n",
    "print(f\"Manual calculation: {manual_norm_A:.2f}\")\n",
    "print(f\"Match: {np.isclose(norm_A, manual_norm_A)}\")\n",
    "\n",
    "# Distance metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DISTANCE METRICS: d(A, B)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "diff = A - B\n",
    "print(\"\\nDifference A - B:\")\n",
    "print(diff)\n",
    "\n",
    "# L2 (Euclidean)\n",
    "l2_dist = np.linalg.norm(diff, 'fro')\n",
    "print(f\"\\nL² distance (Euclidean):\")\n",
    "print(f\"  d(A,B) = ||A-B||_F = √({diff[0,0]**2} + {diff[0,1]**2} + {diff[1,0]**2} + {diff[1,1]**2})\")\n",
    "print(f\"  d(A,B) = {l2_dist:.4f}\")\n",
    "\n",
    "# L1 (Manhattan)\n",
    "l1_dist = np.sum(np.abs(diff))\n",
    "print(f\"\\nL¹ distance (Manhattan):\")\n",
    "print(f\"  d(A,B) = Σ|aᵢⱼ - bᵢⱼ| = {abs(diff[0,0])} + {abs(diff[0,1])} + {abs(diff[1,0])} + {abs(diff[1,1])}\")\n",
    "print(f\"  d(A,B) = {l1_dist:.4f}\")\n",
    "\n",
    "# L∞ (Maximum)\n",
    "linf_dist = np.max(np.abs(diff))\n",
    "print(f\"\\nL∞ distance (Maximum):\")\n",
    "print(f\"  d(A,B) = max|aᵢⱼ - bᵢⱼ| = max({abs(diff[0,0])}, {abs(diff[0,1])}, {abs(diff[1,0])}, {abs(diff[1,1])})\")\n",
    "print(f\"  d(A,B) = {linf_dist:.4f}\")\n",
    "\n",
    "# MSE\n",
    "mse = np.mean(diff**2)\n",
    "print(f\"\\nMean Squared Error (MSE):\")\n",
    "print(f\"  MSE(A,B) = (1/mn) Σ(aᵢⱼ - bᵢⱼ)² = ({diff[0,0]**2} + {diff[0,1]**2} + {diff[1,0]**2} + {diff[1,1]**2})/4\")\n",
    "print(f\"  MSE(A,B) = {mse:.4f}\")\n",
    "\n",
    "# Image comparison demonstration\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMAGE SIMILARITY EXAMPLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create test images\n",
    "img_original = np.random.randint(0, 256, (100, 100), dtype=np.uint8)\n",
    "img_similar = np.clip(img_original.astype(int) + np.random.randint(-10, 10, (100, 100)), 0, 255).astype(np.uint8)\n",
    "img_different = np.random.randint(0, 256, (100, 100), dtype=np.uint8)\n",
    "\n",
    "# Compute distances\n",
    "dist_similar = np.linalg.norm(img_original.astype(float) - img_similar.astype(float))\n",
    "dist_different = np.linalg.norm(img_original.astype(float) - img_different.astype(float))\n",
    "\n",
    "mse_similar = np.mean((img_original.astype(float) - img_similar.astype(float))**2)\n",
    "mse_different = np.mean((img_original.astype(float) - img_different.astype(float))**2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(img_original, cmap='gray')\n",
    "axes[0].set_title('Original Image', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(img_similar, cmap='gray')\n",
    "axes[1].set_title(f'Similar Image\\nL² dist: {dist_similar:.1f}\\nMSE: {mse_similar:.2f}', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(img_different, cmap='gray')\n",
    "axes[2].set_title(f'Different Image\\nL² dist: {dist_different:.1f}\\nMSE: {mse_different:.2f}', fontsize=12)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSimilar image distance: {dist_similar:.2f} (smaller = more similar)\")\n",
    "print(f\"Different image distance: {dist_different:.2f} (larger = less similar)\")\n",
    "print(f\"\\nRatio: {dist_different/dist_similar:.2f}× more different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary-theory",
   "metadata": {},
   "source": [
    "### Summary: Mathematical Foundations\n",
    "\n",
    "You now understand the **theoretical basis** of matrix operations in image processing:\n",
    "\n",
    "#### 1. Matrix Fundamentals\n",
    "- **Definition**: Rectangular arrays $A \\in \\mathbb{R}^{m \\times n}$\n",
    "- **Special matrices**: $\\mathbf{O}$, $\\mathbf{J}$, $\\mathbf{I}$ (black, white, diagonal images)\n",
    "- **Image as matrix**: Grayscale (2D), Color (3D tensor)\n",
    "\n",
    "#### 2. Element-wise Operations\n",
    "- **Addition**: $(A + B)_{ij} = a_{ij} + b_{ij}$ (brightness adjustment)\n",
    "- **Scalar multiplication**: $(c \\cdot A)_{ij} = c \\cdot a_{ij}$ (contrast adjustment)\n",
    "- **Hadamard product**: $(A \\odot B)_{ij} = a_{ij} \\cdot b_{ij}$ (masking)\n",
    "- **Properties**: Commutative, associative, distributive\n",
    "\n",
    "#### 3. Linear Algebra Concepts\n",
    "- **Linear combination**: $C = \\sum_{k=1}^{n} c_k A_k$ (image blending)\n",
    "- **Affine transformation**: $f(\\mathbf{x}) = A\\mathbf{x} + \\mathbf{b}$ (brightness/contrast)\n",
    "- **Vector space**: All linear combinations form a space\n",
    "\n",
    "#### 4. Norms and Metrics\n",
    "- **Frobenius norm**: $\\|A\\|_F = \\sqrt{\\sum_{i,j} a_{ij}^2}$ (image energy)\n",
    "- **Distance metrics**: $d_1$, $d_2$, $d_\\infty$ (image similarity)\n",
    "- **MSE**: $\\text{MSE}(A,B) = \\frac{1}{mn}\\sum_{i,j}(a_{ij}-b_{ij})^2$ (quality metric)\n",
    "\n",
    "#### Key Mathematical Formulas Summary:\n",
    "\n",
    "| Operation | Formula | OpenCV Function |\n",
    "|-----------|---------|----------------|\n",
    "| Addition | $(A + B)_{ij} = a_{ij} + b_{ij}$ | `cv2.add()` |\n",
    "| Scalar Mult | $(c \\cdot A)_{ij} = c \\cdot a_{ij}$ | `cv2.multiply()` |\n",
    "| Linear Combo | $C = \\alpha A + \\beta B + \\gamma$ | `cv2.addWeighted()` |\n",
    "| Frobenius Norm | $\\|A\\|_F = \\sqrt{\\sum_{i,j} a_{ij}^2}$ | `cv2.norm()` |\n",
    "| Euclidean Dist | $d_2(A,B) = \\|A-B\\|_F$ | `cv2.norm(A-B)` |\n",
    "| MSE | $\\frac{1}{mn}\\sum_{i,j}(a_{ij}-b_{ij})^2$ | `np.mean((A-B)**2)` |\n",
    "\n",
    "**Next topic**: We'll build on these fundamentals to understand convolution (Module 3) and geometric transformations (Module 4)!\n",
    "\n",
    "---\n",
    "\n",
    "**Mathematical Notation Guide**:\n",
    "- $A, B, C$: Matrices (capital letters)\n",
    "- $a_{ij}$: Element at row $i$, column $j$\n",
    "- $\\mathbf{x}, \\mathbf{b}$: Vectors (bold lowercase)\n",
    "- $c, \\alpha, \\beta$: Scalars (lowercase)\n",
    "- $\\odot$: Hadamard (element-wise) product\n",
    "- $\\times$: Standard matrix multiplication\n",
    "- $\\|\\cdot\\|_F$: Frobenius norm\n",
    "- $\\mathbb{R}^{m \\times n}$: Set of real $m \\times n$ matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creating Images from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank black image (all zeros)\n",
    "height, width = 300, 400\n",
    "black_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "# Create a white image (all 255s)\n",
    "white_img = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Create a colored image (BGR format)\n",
    "blue_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "blue_img[:, :] = [255, 0, 0]  # Blue in BGR\n",
    "\n",
    "# Display images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(cv2.cvtColor(black_img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Black Image')\n",
    "axes[1].imshow(cv2.cvtColor(white_img, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('White Image')\n",
    "axes[2].imshow(cv2.cvtColor(blue_img, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Blue Image')\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {black_img.shape}\")\n",
    "print(f\"Image dtype: {black_img.dtype}\")\n",
    "print(f\"Image size (bytes): {black_img.nbytes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-matrix-ops-1",
   "metadata": {},
   "source": [
    "### Matrix Operations Explained: Image Creation\n",
    "\n",
    "Let's break down the matrix operations used above:\n",
    "\n",
    "**1. `np.zeros((height, width, 3))` - Creating a zero matrix**\n",
    "```python\n",
    "# Creates a 3D array filled with zeros\n",
    "# Shape: (height, width, 3) where 3 = BGR channels\n",
    "```\n",
    "\n",
    "**2. `np.ones((height, width, 3)) * 255` - Scalar multiplication**\n",
    "```python\n",
    "# Creates array of 1s, then multiplies every element by 255\n",
    "# This is element-wise (scalar) multiplication\n",
    "```\n",
    "\n",
    "**3. `img[:, :]` - Broadcasting assignment**\n",
    "```python\n",
    "# Sets ALL pixels to [255, 0, 0]\n",
    "# [:, :] means \"all rows, all columns\"\n",
    "# The value [255, 0, 0] is broadcast to every pixel\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-matrix-ops-demo-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate these operations on a small matrix\n",
    "print(\"=\" * 60)\n",
    "print(\"MATRIX OPERATION 1: np.zeros()\")\n",
    "print(\"=\" * 60)\n",
    "small_zeros = np.zeros((3, 4), dtype=np.uint8)\n",
    "print(\"np.zeros((3, 4)):\")\n",
    "print(small_zeros)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MATRIX OPERATION 2: Scalar Multiplication\")\n",
    "print(\"=\" * 60)\n",
    "small_ones = np.ones((3, 4), dtype=np.uint8)\n",
    "print(\"np.ones((3, 4)):\")\n",
    "print(small_ones)\n",
    "print(\"\\nnp.ones((3, 4)) * 255:\")\n",
    "print(small_ones * 255)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MATRIX OPERATION 3: Broadcasting\")\n",
    "print(\"=\" * 60)\n",
    "small_3d = np.zeros((2, 3, 3), dtype=np.uint8)\n",
    "print(\"Before: np.zeros((2, 3, 3)):\")\n",
    "print(small_3d)\n",
    "small_3d[:, :] = [100, 150, 200]  # Broadcast to all pixels\n",
    "print(\"\\nAfter: [:, :] = [100, 150, 200]:\")\n",
    "print(small_3d)\n",
    "print(\"\\nNotice: Every pixel now has [100, 150, 200]!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Loading and Displaying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a sample image (for Colab)\n",
    "!wget -q https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/481px-Cat03.jpg -O sample.jpg\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('sample.jpg')\n",
    "\n",
    "# Check if image was loaded successfully\n",
    "if img is None:\n",
    "    print(\"Error: Could not load image\")\n",
    "else:\n",
    "    print(f\"Image loaded successfully!\")\n",
    "    print(f\"Shape: {img.shape} (height, width, channels)\")\n",
    "    print(f\"Data type: {img.dtype}\")\n",
    "    print(f\"Min pixel value: {img.min()}\")\n",
    "    print(f\"Max pixel value: {img.max()}\")\n",
    "    \n",
    "    # Display using matplotlib (convert BGR to RGB)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Understanding Image Coordinates and Pixel Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access individual pixel (y, x) - Remember: row, column!\n",
    "y, x = 100, 150\n",
    "pixel = img[y, x]\n",
    "print(f\"Pixel at ({x}, {y}): BGR = {pixel}\")\n",
    "print(f\"  Blue: {pixel[0]}\")\n",
    "print(f\"  Green: {pixel[1]}\")\n",
    "print(f\"  Red: {pixel[2]}\")\n",
    "\n",
    "# Modify a single pixel\n",
    "img_copy = img.copy()\n",
    "img_copy[y, x] = [0, 0, 255]  # Set to red\n",
    "\n",
    "# Draw a small cross at that pixel for visualization\n",
    "for i in range(-5, 6):\n",
    "    if 0 <= y+i < img_copy.shape[0]:\n",
    "        img_copy[y+i, x] = [0, 255, 0]  # Green vertical line\n",
    "    if 0 <= x+i < img_copy.shape[1]:\n",
    "        img_copy[y, x+i] = [0, 255, 0]  # Green horizontal line\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Pixel at ({x}, {y}) marked with green cross')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ROI using NumPy slicing\n",
    "# Format: img[y_start:y_end, x_start:x_end]\n",
    "roi = img[50:200, 100:300]\n",
    "\n",
    "# Display original and ROI\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].add_patch(plt.Rectangle((100, 50), 200, 150, \n",
    "                                  fill=False, edgecolor='red', linewidth=3))\n",
    "axes[1].imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Extracted ROI')\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original image shape: {img.shape}\")\n",
    "print(f\"ROI shape: {roi.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-matrix-indexing",
   "metadata": {},
   "source": [
    "### Matrix Operations Explained: Indexing and Slicing\n",
    "\n",
    "Pixel access uses NumPy's powerful indexing:\n",
    "\n",
    "**1. Single element access: `img[row, col]`**\n",
    "```python\n",
    "pixel = img[100, 150]  # Gets pixel at row 100, column 150\n",
    "# For color images, this returns a 1D array: [B, G, R]\n",
    "```\n",
    "\n",
    "**2. Channel access: `img[row, col, channel]`**\n",
    "```python\n",
    "blue = img[100, 150, 0]   # Blue channel value\n",
    "green = img[100, 150, 1]  # Green channel value\n",
    "red = img[100, 150, 2]    # Red channel value\n",
    "```\n",
    "\n",
    "**3. Slicing: `img[start:end]`**\n",
    "```python\n",
    "img[0:5, 0:10]  # First 5 rows, first 10 columns\n",
    "```\n",
    "\n",
    "**Important**: NumPy uses `[row, column]` which is `[y, x]` in image coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-indexing-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample 5x5 matrix to demonstrate indexing\n",
    "demo_matrix = np.array([\n",
    "    [10, 20, 30, 40, 50],\n",
    "    [15, 25, 35, 45, 55],\n",
    "    [20, 30, 40, 50, 60],\n",
    "    [25, 35, 45, 55, 65],\n",
    "    [30, 40, 50, 60, 70]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "print(\"Original 5x5 matrix:\")\n",
    "print(demo_matrix)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INDEXING EXAMPLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nSingle element [2, 3]: {demo_matrix[2, 3]}\")\n",
    "print(f\"Single row [1, :]: {demo_matrix[1, :]}\")\n",
    "print(f\"Single column [:, 2]: {demo_matrix[:, 2]}\")\n",
    "\n",
    "print(\"\\nSlicing [1:3, 2:5] (rows 1-2, cols 2-4):\")\n",
    "print(demo_matrix[1:3, 2:5])\n",
    "\n",
    "print(\"\\nEvery other row [::2, :]:\")\n",
    "print(demo_matrix[::2, :])\n",
    "\n",
    "print(\"\\nNegative indexing [-1, :] (last row):\")\n",
    "print(demo_matrix[-1, :])\n",
    "\n",
    "# Visualize the slicing\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Original\n",
    "im1 = axes[0].imshow(demo_matrix, cmap='viridis', interpolation='nearest')\n",
    "axes[0].set_title('Original Matrix (5x5)')\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[0].text(j, i, demo_matrix[i, j], \n",
    "                    ha='center', va='center', color='white', fontsize=10)\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Highlight the slice [1:3, 2:5]\n",
    "highlight = demo_matrix.copy().astype(float)\n",
    "mask = np.zeros_like(highlight)\n",
    "mask[1:3, 2:5] = 1\n",
    "highlight[mask == 0] = np.nan  # Make unselected areas transparent\n",
    "\n",
    "axes[1].imshow(demo_matrix, cmap='gray', alpha=0.3, interpolation='nearest')\n",
    "im2 = axes[1].imshow(highlight, cmap='viridis', interpolation='nearest')\n",
    "axes[1].set_title('Slice [1:3, 2:5] Highlighted')\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        color = 'red' if (1 <= i < 3 and 2 <= j < 5) else 'black'\n",
    "        weight = 'bold' if (1 <= i < 3 and 2 <= j < 5) else 'normal'\n",
    "        axes[1].text(j, i, demo_matrix[i, j], \n",
    "                    ha='center', va='center', color=color, \n",
    "                    fontsize=10, fontweight=weight)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Color Channel Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split image into B, G, R channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Alternative method using NumPy indexing\n",
    "b_alt = img[:, :, 0]\n",
    "g_alt = img[:, :, 1]\n",
    "r_alt = img[:, :, 2]\n",
    "\n",
    "# Display individual channels\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original')\n",
    "\n",
    "# Blue channel\n",
    "axes[0, 1].imshow(b, cmap='Blues')\n",
    "axes[0, 1].set_title('Blue Channel')\n",
    "\n",
    "# Green channel\n",
    "axes[1, 0].imshow(g, cmap='Greens')\n",
    "axes[1, 0].set_title('Green Channel')\n",
    "\n",
    "# Red channel\n",
    "axes[1, 1].imshow(r, cmap='Reds')\n",
    "axes[1, 1].set_title('Red Channel')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Merging Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-roi-matrix",
   "metadata": {},
   "source": [
    "### Matrix Operations Explained: ROI Extraction\n",
    "\n",
    "ROI extraction is just **matrix slicing** applied to images!\n",
    "\n",
    "**Syntax**: `img[y_start:y_end, x_start:x_end]`\n",
    "\n",
    "**What happens**:\n",
    "1. Creates a **view** (not a copy) of the original array\n",
    "2. Extracts a rectangular sub-matrix\n",
    "3. Maintains the same data type and channel structure\n",
    "\n",
    "**Important Properties**:\n",
    "- Slicing returns a **view**: Modifying the ROI modifies the original!\n",
    "- Use `.copy()` to create an independent copy\n",
    "- Negative indices work: `img[-100:, -100:]` = bottom-right corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-roi-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate ROI as a view vs copy\n",
    "test_img = np.random.randint(0, 256, (200, 300, 3), dtype=np.uint8)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ROI AS VIEW (modifying affects original)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extract ROI as view\n",
    "roi_view = test_img[50:100, 50:100]\n",
    "print(f\"Original shape: {test_img.shape}\")\n",
    "print(f\"ROI view shape: {roi_view.shape}\")\n",
    "\n",
    "# Modify the ROI\n",
    "roi_view[:, :] = [0, 255, 0]  # Set to green\n",
    "\n",
    "print(\"\\nAfter modifying ROI view:\")\n",
    "print(\"- ROI is green: ✓\")\n",
    "print(\"- Original image ALSO modified: ✓ (because it's a view!)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ROI AS COPY (modifying does NOT affect original)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Reset\n",
    "test_img = np.random.randint(0, 256, (200, 300, 3), dtype=np.uint8)\n",
    "\n",
    "# Extract ROI as copy\n",
    "roi_copy = test_img[50:100, 50:100].copy()\n",
    "\n",
    "# Modify the copy\n",
    "roi_copy[:, :] = [255, 0, 0]  # Set to red\n",
    "\n",
    "print(\"After modifying ROI copy:\")\n",
    "print(\"- ROI copy is red: ✓\")\n",
    "print(\"- Original image unchanged: ✓ (because it's a copy!)\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Show the view example\n",
    "test_img_view = np.random.randint(0, 256, (200, 300, 3), dtype=np.uint8)\n",
    "test_img_view[50:100, 50:100] = [0, 255, 0]\n",
    "axes[0].imshow(cv2.cvtColor(test_img_view, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('ROI as View\\n(original modified)', fontsize=12)\n",
    "axes[0].add_patch(plt.Rectangle((50, 50), 50, 50, \n",
    "                                fill=False, edgecolor='yellow', linewidth=3))\n",
    "\n",
    "# Show the copy example\n",
    "axes[1].imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('ROI as Copy\\n(original unchanged)', fontsize=12)\n",
    "axes[1].add_patch(plt.Rectangle((50, 50), 50, 50, \n",
    "                                fill=False, edgecolor='yellow', linewidth=3))\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPro Tip: Use .copy() when you want to preserve the original!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modified images by zeroing out channels\n",
    "zeros = np.zeros_like(b)\n",
    "\n",
    "# Only blue channel\n",
    "only_blue = cv2.merge([b, zeros, zeros])\n",
    "\n",
    "# Only green channel\n",
    "only_green = cv2.merge([zeros, g, zeros])\n",
    "\n",
    "# Only red channel\n",
    "only_red = cv2.merge([zeros, zeros, r])\n",
    "\n",
    "# Swap channels (BGR to RGB)\n",
    "rgb = cv2.merge([r, g, b])\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(only_blue, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Only Blue Channel')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(only_green, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Only Green Channel')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(only_red, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Only Red Channel')\n",
    "\n",
    "axes[1, 1].imshow(rgb)  # Already in RGB order\n",
    "axes[1, 1].set_title('BGR to RGB Swapped')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Image Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brighten image\n",
    "brightened = cv2.add(img, np.array([50.0]))  # Safe addition with saturation\n",
    "\n",
    "# Darken image\n",
    "darkened = cv2.subtract(img, np.array([50.0]))  # Safe subtraction\n",
    "\n",
    "# Increase contrast (multiply)\n",
    "contrast = cv2.multiply(img, np.array([1.5]))  # 1.5x brightness\n",
    "\n",
    "# Blend two images\n",
    "blended = cv2.addWeighted(img, 0.7, brightened, 0.3, 0)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(brightened, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Brightened (+50)')\n",
    "\n",
    "axes[0, 2].imshow(cv2.cvtColor(darkened, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 2].set_title('Darkened (-50)')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(contrast, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('High Contrast (1.5x)')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title('Blended (70%/30%)')\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "for ax in axes.flat[:-1]:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-channel-matrix",
   "metadata": {},
   "source": [
    "### Matrix Operations Explained: Channel Splitting\n",
    "\n",
    "Color images are **3D matrices**: `(height, width, 3)`\n",
    "\n",
    "**Two methods to split channels**:\n",
    "\n",
    "**Method 1: `cv2.split(img)`**\n",
    "```python\n",
    "b, g, r = cv2.split(img)\n",
    "# Returns 3 separate 2D arrays\n",
    "```\n",
    "\n",
    "**Method 2: NumPy indexing `img[:, :, channel]`**\n",
    "```python\n",
    "b = img[:, :, 0]  # All rows, all cols, channel 0 (blue)\n",
    "g = img[:, :, 1]  # All rows, all cols, channel 1 (green)\n",
    "r = img[:, :, 2]  # All rows, all cols, channel 2 (red)\n",
    "```\n",
    "\n",
    "**Which is better?**\n",
    "- `cv2.split()`: Cleaner syntax, creates copies\n",
    "- NumPy indexing: More flexible, returns views (faster)\n",
    "\n",
    "**Matrix perspective**:\n",
    "- A 3D array can be thought of as 3 stacked 2D arrays (one per channel)\n",
    "- Splitting extracts each 2D slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-channel-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 3D structure of color images\n",
    "small_color = np.array([\n",
    "    [[255, 0, 0], [0, 255, 0], [0, 0, 255]],\n",
    "    [[255, 255, 0], [255, 0, 255], [0, 255, 255]],\n",
    "    [[128, 128, 128], [255, 255, 255], [0, 0, 0]]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "print(\"3x3 color image (BGR format):\")\n",
    "print(\"Shape:\", small_color.shape, \"-> (height=3, width=3, channels=3)\")\n",
    "print(\"\\nFull array:\")\n",
    "print(small_color)\n",
    "\n",
    "# Split using both methods\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"METHOD 1: cv2.split()\")\n",
    "print(\"=\" * 60)\n",
    "b1, g1, r1 = cv2.split(small_color)\n",
    "print(\"Blue channel:\")\n",
    "print(b1)\n",
    "print(\"\\nGreen channel:\")\n",
    "print(g1)\n",
    "print(\"\\nRed channel:\")\n",
    "print(r1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"METHOD 2: NumPy indexing\")\n",
    "print(\"=\" * 60)\n",
    "b2 = small_color[:, :, 0]\n",
    "g2 = small_color[:, :, 1]\n",
    "r2 = small_color[:, :, 2]\n",
    "print(\"Blue channel [:, :, 0]:\")\n",
    "print(b2)\n",
    "print(\"\\nGreen channel [:, :, 1]:\")\n",
    "print(g2)\n",
    "print(\"\\nRed channel [:, :, 2]:\")\n",
    "print(r2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Blue channels equal: {np.array_equal(b1, b2)}\")\n",
    "print(f\"Green channels equal: {np.array_equal(g1, g2)}\")\n",
    "print(f\"Red channels equal: {np.array_equal(r1, r2)}\")\n",
    "\n",
    "# Visualize the 3D structure\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Original color image\n",
    "ax1 = plt.subplot(1, 4, 1)\n",
    "ax1.imshow(cv2.cvtColor(small_color, cv2.COLOR_BGR2RGB))\n",
    "ax1.set_title('Original\\n(3D: H×W×3)', fontsize=12)\n",
    "ax1.axis('off')\n",
    "\n",
    "# Individual channels\n",
    "channels = [(b1, 'Blue\\nChannel 0', 'Blues'),\n",
    "            (g1, 'Green\\nChannel 1', 'Greens'),\n",
    "            (r1, 'Red\\nChannel 2', 'Reds')]\n",
    "\n",
    "for idx, (channel, title, cmap) in enumerate(channels, 2):\n",
    "    ax = plt.subplot(1, 4, idx)\n",
    "    ax.imshow(channel, cmap=cmap, vmin=0, vmax=255)\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: Channel splitting extracts 2D slices from the 3D array!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed images\n",
    "cv2.imwrite('brightened.jpg', brightened)\n",
    "cv2.imwrite('darkened.jpg', darkened)\n",
    "cv2.imwrite('roi.jpg', roi)\n",
    "\n",
    "# Save with different quality (JPEG)\n",
    "cv2.imwrite('low_quality.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 50])\n",
    "cv2.imwrite('high_quality.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "\n",
    "# Save as PNG (lossless)\n",
    "cv2.imwrite('lossless.png', img)\n",
    "\n",
    "print(\"Images saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try these exercises to reinforce your learning:\n",
    "\n",
    "1. **Create a gradient image**: Create a 256x256 image where pixel intensity increases from left to right\n",
    "2. **Chessboard pattern**: Create an 8x8 chessboard pattern (black and white squares)\n",
    "3. **Image watermark**: Add your name as text to an image\n",
    "4. **Color swap**: Swap red and blue channels in an image\n",
    "5. **Negative image**: Create the negative of an image (255 - pixel_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Gradient image\n",
    "gradient = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "for x in range(256):\n",
    "    gradient[:, x] = [x, x, x]\n",
    "\n",
    "plt.imshow(gradient)\n",
    "plt.title('Gradient Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-arithmetic-matrix",
   "metadata": {},
   "source": [
    "### Matrix Operations Explained: Image Arithmetic\n",
    "\n",
    "Image arithmetic uses **element-wise matrix operations**.\n",
    "\n",
    "**1. Addition: `cv2.add(img1, img2)`**\n",
    "```python\n",
    "# Element-wise addition with saturation\n",
    "# result[i,j] = min(img1[i,j] + img2[i,j], 255)\n",
    "```\n",
    "\n",
    "**2. Subtraction: `cv2.subtract(img1, img2)`**\n",
    "```python\n",
    "# Element-wise subtraction with saturation\n",
    "# result[i,j] = max(img1[i,j] - img2[i,j], 0)\n",
    "```\n",
    "\n",
    "**3. Multiplication: `cv2.multiply(img, scalar)`**\n",
    "```python\n",
    "# Element-wise scalar multiplication\n",
    "# result[i,j] = min(img[i,j] * scalar, 255)\n",
    "```\n",
    "\n",
    "**4. Weighted sum: `cv2.addWeighted(img1, α, img2, β, γ)`**\n",
    "```python\n",
    "# Computes: result = α*img1 + β*img2 + γ\n",
    "# This is a linear combination of matrices!\n",
    "```\n",
    "\n",
    "**Why use OpenCV functions instead of NumPy `+`, `-`, `*`?**\n",
    "- **Saturation**: OpenCV clips values to [0, 255]\n",
    "- **NumPy**: Can overflow (256 wraps to 0)\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "a = np.array([250], dtype=np.uint8)\n",
    "a + 10         # = 4 (overflow!)\n",
    "cv2.add(a, 10) # = 255 (saturated)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-arithmetic-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the difference between NumPy and OpenCV arithmetic\n",
    "print(\"=\" * 60)\n",
    "print(\"SATURATION vs OVERFLOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create test arrays\n",
    "test1 = np.array([250, 200, 100, 50], dtype=np.uint8)\n",
    "test2 = np.array([10, 60, 200, 250], dtype=np.uint8)\n",
    "\n",
    "print(f\"Array 1: {test1}\")\n",
    "print(f\"Array 2: {test2}\")\n",
    "\n",
    "# NumPy addition (can overflow)\n",
    "numpy_add = test1 + test2\n",
    "print(f\"\\nNumPy addition (test1 + test2):\")\n",
    "print(f\"  Result: {numpy_add}\")\n",
    "print(f\"  Note: 250+10=260, but wraps to {numpy_add[0]} (overflow!)\")\n",
    "\n",
    "# OpenCV addition (saturates)\n",
    "opencv_add = cv2.add(test1, test2)\n",
    "print(f\"\\nOpenCV addition cv2.add(test1, test2):\")\n",
    "print(f\"  Result: {opencv_add}\")\n",
    "print(f\"  Note: 250+10=260, clips to {opencv_add[0]} (saturation!)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WEIGHTED SUM (Linear Combination)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create two small test images\n",
    "img1_test = np.full((3, 3), 100, dtype=np.uint8)\n",
    "img2_test = np.full((3, 3), 200, dtype=np.uint8)\n",
    "\n",
    "print(\"Image 1 (all 100):\")\n",
    "print(img1_test)\n",
    "print(\"\\nImage 2 (all 200):\")\n",
    "print(img2_test)\n",
    "\n",
    "# Blend with different weights\n",
    "alpha = 0.3\n",
    "beta = 0.7\n",
    "gamma = 0\n",
    "\n",
    "blended = cv2.addWeighted(img1_test, alpha, img2_test, beta, gamma)\n",
    "\n",
    "print(f\"\\nWeighted sum: {alpha}*img1 + {beta}*img2 + {gamma}\")\n",
    "print(f\"Expected: {alpha}*100 + {beta}*200 = {alpha*100 + beta*200}\")\n",
    "print(f\"Result:\")\n",
    "print(blended)\n",
    "\n",
    "# Visualize element-wise operations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Create gradient images for better visualization\n",
    "grad1 = np.linspace(0, 255, 100).reshape(1, 100).repeat(100, axis=0).astype(np.uint8)\n",
    "grad2 = np.linspace(255, 0, 100).reshape(1, 100).repeat(100, axis=0).astype(np.uint8)\n",
    "\n",
    "# Addition\n",
    "added = cv2.add(grad1, grad2)\n",
    "axes[0, 0].imshow(grad1, cmap='gray')\n",
    "axes[0, 0].set_title('Image 1\\n(0→255)', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(grad2, cmap='gray')\n",
    "axes[0, 1].set_title('Image 2\\n(255→0)', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(added, cmap='gray')\n",
    "axes[0, 2].set_title('Addition\\ncv2.add()', fontsize=12)\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Subtraction\n",
    "subtracted = cv2.subtract(grad1, grad2)\n",
    "axes[1, 0].imshow(subtracted, cmap='gray')\n",
    "axes[1, 0].set_title('Subtraction\\ncv2.subtract()', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Weighted blend\n",
    "blend_viz = cv2.addWeighted(grad1, 0.5, grad2, 0.5, 0)\n",
    "axes[1, 1].imshow(blend_viz, cmap='gray')\n",
    "axes[1, 1].set_title('Weighted Blend\\n0.5×img1 + 0.5×img2', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Multiplication\n",
    "multiplied = cv2.multiply(grad1, np.array([2.0]))\n",
    "axes[1, 2].imshow(multiplied, cmap='gray')\n",
    "axes[1, 2].set_title('Multiplication\\ncv2.multiply(×2)', fontsize=12)\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Takeaway: Image arithmetic is element-wise matrix operations!\")\n",
    "print(\"Always use cv2 functions to avoid overflow/underflow issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Chessboard pattern\n",
    "chessboard = np.zeros((400, 400), dtype=np.uint8)\n",
    "square_size = 50\n",
    "\n",
    "for i in range(0, 8):\n",
    "    for j in range(0, 8):\n",
    "        if (i + j) % 2 == 0:\n",
    "            chessboard[i*square_size:(i+1)*square_size, \n",
    "                      j*square_size:(j+1)*square_size] = 255\n",
    "\n",
    "plt.imshow(chessboard, cmap='gray')\n",
    "plt.title('Chessboard Pattern')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Negative image\n",
    "negative = 255 - img\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[1].imshow(cv2.cvtColor(negative, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Negative')\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, you learned:\n",
    "- Images are NumPy arrays with shape (height, width, channels)\n",
    "- OpenCV uses BGR color format (not RGB!)\n",
    "- How to access and modify pixels using array indexing\n",
    "- ROI extraction using NumPy slicing\n",
    "- Channel splitting and merging\n",
    "- Basic image arithmetic operations\n",
    "- Saving images in different formats\n",
    "\n",
    "**Next**: Module 2 - Drawing & Color Spaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}